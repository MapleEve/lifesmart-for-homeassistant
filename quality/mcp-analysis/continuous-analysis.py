#!/usr/bin/env python3
"""
Context MCPæŒç»­åˆ†æå·¥ä½œæµç¨‹

åŸºäºZENä¸“å®¶æŒ‡å¯¼ï¼Œé›†æˆMCPåˆ°è´¨é‡ä¿éšœæµç¨‹ä¸­ã€‚
æä¾›æŒç»­ä»£ç åˆ†æã€è´¨é‡è¶‹åŠ¿è·Ÿè¸ªå’ŒæŠ€æœ¯å€ºåŠ¡æ£€æµ‹ã€‚
"""

import json
import pathlib
import subprocess
import sys
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional


@dataclass
class AnalysisResult:
    """MCPåˆ†æç»“æœ"""

    timestamp: str
    project_path: str
    analysis_type: str
    status: str  # SUCCESS, FAILED, WARNING
    metrics: Dict[str, Any]
    insights: List[str]
    recommendations: List[str]
    technical_debt: Dict[str, Any]
    trends: Dict[str, Any]
    execution_time: float


@dataclass
class ContinuousAnalysisReport:
    """æŒç»­åˆ†ææŠ¥å‘Š"""

    report_id: str
    start_time: str
    end_time: str
    project_path: str
    total_analyses: int
    successful_analyses: int
    failed_analyses: int
    overall_quality_score: float
    trend_analysis: Dict[str, Any]
    critical_findings: List[str]
    results: List[AnalysisResult]


class MCPContinuousAnalyzer:
    """
    MCPæŒç»­åˆ†æå™¨

    é›†æˆå„ç§MCPå·¥å…·æä¾›æŒç»­ä»£ç åˆ†æã€‚
    """

    def __init__(self, project_root: pathlib.Path):
        self.project_root = project_root
        self.config = self._load_config()
        self.analysis_history = self._load_history()
        self.mcp_tools = self._initialize_mcp_tools()

    def _load_config(self) -> Dict[str, Any]:
        """åŠ è½½MCPåˆ†æé…ç½®"""
        config_file = self.project_root / "quality" / "mcp-analysis" / "mcp-config.json"

        default_config = {
            "analysis_intervals": {
                "code_quality": "daily",
                "architecture_review": "weekly",
                "tech_debt_scan": "daily",
                "performance_analysis": "weekly",
            },
            "quality_thresholds": {
                "min_quality_score": 85.0,
                "max_tech_debt_items": 10,
                "critical_issue_threshold": 3,
            },
            "mcp_tools": {
                "context_mcp": {"enabled": True, "priority": "high"},
                "context7": {"enabled": True, "priority": "medium"},
            },
            "analysis_scope": ["custom_components/lifesmart", "quality/"],
            "exclude_patterns": ["*/tests/*", "*/__pycache__/*", "*/tmp/*"],
        }

        if config_file.exists():
            try:
                with open(config_file, "r", encoding="utf-8") as f:
                    user_config = json.load(f)
                    default_config.update(user_config)
            except Exception as e:
                print(f"è­¦å‘Š: æ— æ³•åŠ è½½MCPé…ç½® {config_file}: {e}")

        return default_config

    def _load_history(self) -> List[Dict[str, Any]]:
        """åŠ è½½åˆ†æå†å²"""
        history_file = (
            self.project_root
            / "quality"
            / "mcp-analysis"
            / "data"
            / "analysis_history.json"
        )

        if history_file.exists():
            try:
                with open(history_file, "r", encoding="utf-8") as f:
                    return json.load(f)
            except Exception as e:
                print(f"è­¦å‘Š: æ— æ³•åŠ è½½åˆ†æå†å² {history_file}: {e}")

        return []

    def _save_history(self):
        """ä¿å­˜åˆ†æå†å²"""
        history_file = (
            self.project_root
            / "quality"
            / "mcp-analysis"
            / "data"
            / "analysis_history.json"
        )
        history_file.parent.mkdir(parents=True, exist_ok=True)

        try:
            with open(history_file, "w", encoding="utf-8") as f:
                json.dump(
                    self.analysis_history, f, indent=2, ensure_ascii=False, default=str
                )
        except Exception as e:
            print(f"è­¦å‘Š: æ— æ³•ä¿å­˜åˆ†æå†å²: {e}")

    def _initialize_mcp_tools(self) -> Dict[str, Any]:
        """åˆå§‹åŒ–MCPå·¥å…·"""
        return {
            "code_quality_analyzer": self._create_code_quality_analyzer(),
            "architecture_reviewer": self._create_architecture_reviewer(),
            "tech_debt_detector": self._create_tech_debt_detector(),
            "performance_analyzer": self._create_performance_analyzer(),
        }

    def run_continuous_analysis(
        self, analysis_types: Optional[List[str]] = None, force_run: bool = False
    ) -> ContinuousAnalysisReport:
        """
        è¿è¡ŒæŒç»­åˆ†ææµç¨‹

        Args:
            analysis_types: æŒ‡å®šåˆ†æç±»å‹ï¼Œé»˜è®¤è¿è¡Œæ‰€æœ‰
            force_run: å¼ºåˆ¶è¿è¡Œï¼Œå¿½ç•¥æ—¶é—´é—´éš”é™åˆ¶
        """
        start_time = datetime.now()
        report_id = f"mcp-analysis-{start_time.strftime('%Y%m%d-%H%M%S')}"

        print(f"ğŸ” å¼€å§‹MCPæŒç»­åˆ†æ...")
        print(f"ğŸ“‹ æŠ¥å‘ŠID: {report_id}")
        print(f"â° å¼€å§‹æ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 60)

        # ç¡®å®šè¦è¿è¡Œçš„åˆ†æç±»å‹
        if analysis_types is None:
            analysis_types = list(self.mcp_tools.keys())

        results = []
        successful = 0
        failed = 0

        # æ‰§è¡Œå„é¡¹åˆ†æ
        for analysis_type in analysis_types:
            if not self._should_run_analysis(analysis_type, force_run):
                print(f"â­ï¸ è·³è¿‡åˆ†æ: {analysis_type} (æœªåˆ°è¿è¡Œæ—¶é—´)")
                continue

            print(f"ğŸ”¬ è¿è¡Œåˆ†æ: {analysis_type}")
            analysis_start = datetime.now()

            try:
                result = self._run_single_analysis(analysis_type)
                result.execution_time = (
                    datetime.now() - analysis_start
                ).total_seconds()
                results.append(result)

                if result.status == "SUCCESS":
                    successful += 1
                    print(f"   âœ… åˆ†æå®Œæˆ: {result.status}")
                else:
                    failed += 1
                    print(f"   âš ï¸ åˆ†æå®Œæˆ: {result.status}")

            except Exception as e:
                failed += 1
                error_result = AnalysisResult(
                    timestamp=datetime.now().isoformat(),
                    project_path=str(self.project_root),
                    analysis_type=analysis_type,
                    status="FAILED",
                    metrics={},
                    insights=[],
                    recommendations=[f"ä¿®å¤åˆ†æå™¨é”™è¯¯: {str(e)}"],
                    technical_debt={},
                    trends={},
                    execution_time=(datetime.now() - analysis_start).total_seconds(),
                )
                results.append(error_result)
                print(f"   âŒ åˆ†æå¤±è´¥: {e}")

        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        end_time = datetime.now()

        # è®¡ç®—è´¨é‡è¯„åˆ†å’Œè¶‹åŠ¿
        overall_quality_score = self._calculate_quality_score(results)
        trend_analysis = self._analyze_trends(results)
        critical_findings = self._extract_critical_findings(results)

        report = ContinuousAnalysisReport(
            report_id=report_id,
            start_time=start_time.isoformat(),
            end_time=end_time.isoformat(),
            project_path=str(self.project_root),
            total_analyses=len(results),
            successful_analyses=successful,
            failed_analyses=failed,
            overall_quality_score=overall_quality_score,
            trend_analysis=trend_analysis,
            critical_findings=critical_findings,
            results=results,
        )

        # æ›´æ–°å†å²è®°å½•
        self._update_analysis_history(report)

        # æ‰“å°æ‘˜è¦
        self._print_analysis_summary(report)

        return report

    def _should_run_analysis(self, analysis_type: str, force_run: bool) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è¿è¡ŒæŒ‡å®šåˆ†æ"""
        if force_run:
            return True

        intervals = self.config.get("analysis_intervals", {})
        interval = intervals.get(analysis_type, "daily")

        # æŸ¥æ‰¾æœ€åä¸€æ¬¡è¿è¡Œæ—¶é—´
        last_run = None
        for record in reversed(self.analysis_history):
            for result in record.get("results", []):
                if result.get("analysis_type") == analysis_type:
                    last_run = datetime.fromisoformat(result["timestamp"])
                    break
            if last_run:
                break

        if not last_run:
            return True

        # è®¡ç®—æ—¶é—´é—´éš”
        now = datetime.now()
        if interval == "daily":
            return now - last_run >= timedelta(days=1)
        elif interval == "weekly":
            return now - last_run >= timedelta(weeks=1)
        elif interval == "hourly":
            return now - last_run >= timedelta(hours=1)

        return True

    def _run_single_analysis(self, analysis_type: str) -> AnalysisResult:
        """è¿è¡Œå•ä¸ªåˆ†æ"""
        analyzer = self.mcp_tools.get(analysis_type)
        if not analyzer:
            raise ValueError(f"æœªçŸ¥çš„åˆ†æç±»å‹: {analysis_type}")

        return analyzer()

    def _create_code_quality_analyzer(self):
        """åˆ›å»ºä»£ç è´¨é‡åˆ†æå™¨"""

        def analyze() -> AnalysisResult:
            """ä»£ç è´¨é‡åˆ†æ"""
            # é›†æˆè´¨é‡é—¨ç¦ç³»ç»Ÿçš„ç»“æœ
            quality_gate_script = (
                self.project_root / "quality" / "ci-cd" / "quality-gate.py"
            )

            if quality_gate_script.exists():
                cmd = [
                    sys.executable,
                    str(quality_gate_script),
                    "--project-root",
                    str(self.project_root),
                    "--save-report",
                    "/tmp/mcp_quality_report.json",
                ]

                try:
                    result = subprocess.run(
                        cmd, capture_output=True, text=True, timeout=300
                    )

                    # è§£æè´¨é‡æŠ¥å‘Š
                    if pathlib.Path("/tmp/mcp_quality_report.json").exists():
                        with open("/tmp/mcp_quality_report.json", "r") as f:
                            quality_data = json.load(f)

                        metrics = {
                            "total_checks": quality_data.get("total_checks", 0),
                            "passed_checks": quality_data.get("passed_checks", 0),
                            "failed_checks": quality_data.get("failed_checks", 0),
                            "warning_checks": quality_data.get("warning_checks", 0),
                            "quality_score": self._calculate_quality_score_from_checks(
                                quality_data
                            ),
                        }

                        insights = [
                            f"è´¨é‡æ£€æŸ¥é€šè¿‡ç‡: {(metrics['passed_checks']/max(metrics['total_checks'],1)*100):.1f}%",
                            f"å‘ç°é—®é¢˜æ•°é‡: {metrics['failed_checks'] + metrics['warning_checks']}",
                        ]

                        recommendations = []
                        if metrics["failed_checks"] > 0:
                            recommendations.append("ä¿®å¤å¤±è´¥çš„è´¨é‡æ£€æŸ¥é¡¹")
                        if metrics["warning_checks"] > 3:
                            recommendations.append("å…³æ³¨è´¨é‡è­¦å‘Šé¡¹ï¼Œé˜²æ­¢é—®é¢˜ç§¯ç´¯")

                        return AnalysisResult(
                            timestamp=datetime.now().isoformat(),
                            project_path=str(self.project_root),
                            analysis_type="code_quality_analyzer",
                            status="SUCCESS",
                            metrics=metrics,
                            insights=insights,
                            recommendations=recommendations,
                            technical_debt={},
                            trends={},
                            execution_time=0.0,
                        )
                except subprocess.TimeoutExpired:
                    pass

            # fallbackåˆ†æ
            return self._basic_code_quality_analysis()

        return analyze

    def _create_architecture_reviewer(self):
        """åˆ›å»ºæ¶æ„å®¡æŸ¥å™¨"""

        def analyze() -> AnalysisResult:
            """æ¶æ„è´¨é‡åˆ†æ"""
            # åˆ†æé¡¹ç›®æ¶æ„å¥åº·åº¦
            architecture_metrics = self._analyze_architecture_health()

            return AnalysisResult(
                timestamp=datetime.now().isoformat(),
                project_path=str(self.project_root),
                analysis_type="architecture_reviewer",
                status="SUCCESS",
                metrics=architecture_metrics,
                insights=self._generate_architecture_insights(architecture_metrics),
                recommendations=self._generate_architecture_recommendations(
                    architecture_metrics
                ),
                technical_debt={},
                trends={},
                execution_time=0.0,
            )

        return analyze

    def _create_tech_debt_detector(self):
        """åˆ›å»ºæŠ€æœ¯å€ºåŠ¡æ£€æµ‹å™¨"""

        def analyze() -> AnalysisResult:
            """æŠ€æœ¯å€ºåŠ¡æ£€æµ‹åˆ†æ"""
            tech_debt = self._detect_technical_debt()

            return AnalysisResult(
                timestamp=datetime.now().isoformat(),
                project_path=str(self.project_root),
                analysis_type="tech_debt_detector",
                status="SUCCESS",
                metrics={"total_debt_items": len(tech_debt.get("items", []))},
                insights=self._generate_tech_debt_insights(tech_debt),
                recommendations=self._generate_tech_debt_recommendations(tech_debt),
                technical_debt=tech_debt,
                trends={},
                execution_time=0.0,
            )

        return analyze

    def _create_performance_analyzer(self):
        """åˆ›å»ºæ€§èƒ½åˆ†æå™¨"""

        def analyze() -> AnalysisResult:
            """æ€§èƒ½åˆ†æ"""
            perf_metrics = self._analyze_performance_metrics()

            return AnalysisResult(
                timestamp=datetime.now().isoformat(),
                project_path=str(self.project_root),
                analysis_type="performance_analyzer",
                status="SUCCESS",
                metrics=perf_metrics,
                insights=self._generate_performance_insights(perf_metrics),
                recommendations=self._generate_performance_recommendations(
                    perf_metrics
                ),
                technical_debt={},
                trends={},
                execution_time=0.0,
            )

        return analyze

    def _basic_code_quality_analysis(self) -> AnalysisResult:
        """åŸºç¡€ä»£ç è´¨é‡åˆ†æ"""
        # ç»Ÿè®¡ä»£ç è¡Œæ•°ã€æ–‡ä»¶æ•°ç­‰åŸºç¡€æŒ‡æ ‡
        python_files = list(self.project_root.rglob("*.py"))
        total_lines = 0

        for py_file in python_files:
            if any(
                pattern in str(py_file)
                for pattern in self.config.get("exclude_patterns", [])
            ):
                continue
            try:
                with open(py_file, "r", encoding="utf-8") as f:
                    total_lines += len(f.readlines())
            except:
                continue

        metrics = {
            "python_files": len(python_files),
            "total_lines": total_lines,
            "avg_lines_per_file": total_lines / max(len(python_files), 1),
        }

        insights = [
            f"é¡¹ç›®åŒ…å« {len(python_files)} ä¸ªPythonæ–‡ä»¶",
            f"æ€»ä»£ç è¡Œæ•°: {total_lines:,}",
            f"å¹³å‡æ¯æ–‡ä»¶è¡Œæ•°: {metrics['avg_lines_per_file']:.0f}",
        ]

        return AnalysisResult(
            timestamp=datetime.now().isoformat(),
            project_path=str(self.project_root),
            analysis_type="code_quality_analyzer",
            status="SUCCESS",
            metrics=metrics,
            insights=insights,
            recommendations=[],
            technical_debt={},
            trends={},
            execution_time=0.0,
        )

    def _calculate_quality_score_from_checks(
        self, quality_data: Dict[str, Any]
    ) -> float:
        """ä»è´¨é‡æ£€æŸ¥æ•°æ®è®¡ç®—è´¨é‡è¯„åˆ†"""
        total = quality_data.get("total_checks", 0)
        passed = quality_data.get("passed_checks", 0)

        if total == 0:
            return 0.0

        return (passed / total) * 100.0

    def _analyze_architecture_health(self) -> Dict[str, Any]:
        """åˆ†ææ¶æ„å¥åº·åº¦"""
        # ç®€åŒ–çš„æ¶æ„åˆ†æ
        return {
            "module_count": len(list(self.project_root.rglob("*.py"))),
            "package_depth": self._calculate_package_depth(),
            "circular_imports": 0,  # ç®€åŒ–å®ç°
        }

    def _calculate_package_depth(self) -> int:
        """è®¡ç®—åŒ…å±‚æ¬¡æ·±åº¦"""
        max_depth = 0
        for py_file in self.project_root.rglob("*.py"):
            depth = len(py_file.relative_to(self.project_root).parts) - 1
            max_depth = max(max_depth, depth)
        return max_depth

    def _detect_technical_debt(self) -> Dict[str, Any]:
        """æ£€æµ‹æŠ€æœ¯å€ºåŠ¡"""
        debt_items = []

        # æŸ¥æ‰¾TODOã€FIXMEã€HACKç­‰æ ‡è®°
        for py_file in self.project_root.rglob("*.py"):
            if any(
                pattern in str(py_file)
                for pattern in self.config.get("exclude_patterns", [])
            ):
                continue

            try:
                with open(py_file, "r", encoding="utf-8") as f:
                    lines = f.readlines()

                for i, line in enumerate(lines, 1):
                    if any(
                        marker in line.upper()
                        for marker in ["TODO", "FIXME", "HACK", "XXX"]
                    ):
                        debt_items.append(
                            {
                                "file": str(py_file),
                                "line": i,
                                "content": line.strip(),
                                "type": "code_marker",
                            }
                        )
            except:
                continue

        return {
            "items": debt_items,
            "total_count": len(debt_items),
            "types": {"code_marker": len(debt_items)},
        }

    def _analyze_performance_metrics(self) -> Dict[str, Any]:
        """åˆ†ææ€§èƒ½æŒ‡æ ‡"""
        # ç®€åŒ–çš„æ€§èƒ½åˆ†æ
        return {
            "file_size_mb": sum(
                f.stat().st_size for f in self.project_root.rglob("*.py")
            )
            / (1024 * 1024),
            "import_complexity": self._calculate_import_complexity(),
        }

    def _calculate_import_complexity(self) -> int:
        """è®¡ç®—å¯¼å…¥å¤æ‚åº¦"""
        total_imports = 0
        for py_file in self.project_root.rglob("*.py"):
            try:
                with open(py_file, "r", encoding="utf-8") as f:
                    for line in f:
                        if line.strip().startswith(("import ", "from ")):
                            total_imports += 1
            except:
                continue
        return total_imports

    def _generate_architecture_insights(self, metrics: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆæ¶æ„æ´å¯Ÿ"""
        insights = []

        if metrics.get("package_depth", 0) > 5:
            insights.append("åŒ…å±‚æ¬¡è¾ƒæ·±ï¼Œå¯èƒ½éœ€è¦é‡æ„ç®€åŒ–")

        if metrics.get("module_count", 0) > 100:
            insights.append("æ¨¡å—æ•°é‡è¾ƒå¤šï¼Œå»ºè®®å…³æ³¨æ¨¡å—èŒè´£åˆ’åˆ†")

        return insights

    def _generate_architecture_recommendations(
        self, metrics: Dict[str, Any]
    ) -> List[str]:
        """ç”Ÿæˆæ¶æ„å»ºè®®"""
        recommendations = []

        if metrics.get("package_depth", 0) > 6:
            recommendations.append("è€ƒè™‘é‡æ„æ·±å±‚åŒ…ç»“æ„")

        return recommendations

    def _generate_tech_debt_insights(self, tech_debt: Dict[str, Any]) -> List[str]:
        """ç”ŸæˆæŠ€æœ¯å€ºåŠ¡æ´å¯Ÿ"""
        total = tech_debt.get("total_count", 0)

        if total == 0:
            return ["æœªå‘ç°æ˜æ˜¾çš„æŠ€æœ¯å€ºåŠ¡æ ‡è®°"]
        elif total < 5:
            return [f"å‘ç° {total} ä¸ªæŠ€æœ¯å€ºåŠ¡é¡¹ï¼Œæ•°é‡åˆç†"]
        else:
            return [f"å‘ç° {total} ä¸ªæŠ€æœ¯å€ºåŠ¡é¡¹ï¼Œå»ºè®®ä¼˜å…ˆå¤„ç†"]

    def _generate_tech_debt_recommendations(
        self, tech_debt: Dict[str, Any]
    ) -> List[str]:
        """ç”ŸæˆæŠ€æœ¯å€ºåŠ¡å»ºè®®"""
        total = tech_debt.get("total_count", 0)

        if total > 10:
            return ["ä¼˜å…ˆå¤„ç†æŠ€æœ¯å€ºåŠ¡é¡¹ï¼Œé˜²æ­¢å€ºåŠ¡ç§¯ç´¯"]
        elif total > 5:
            return ["å®šæœŸå›é¡¾å’Œå¤„ç†æŠ€æœ¯å€ºåŠ¡æ ‡è®°"]
        else:
            return []

    def _generate_performance_insights(self, metrics: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆæ€§èƒ½æ´å¯Ÿ"""
        size_mb = metrics.get("file_size_mb", 0)

        insights = [f"é¡¹ç›®ä»£ç å¤§å°: {size_mb:.1f} MB"]

        if size_mb > 10:
            insights.append("é¡¹ç›®è§„æ¨¡è¾ƒå¤§ï¼Œå…³æ³¨ä»£ç æ¨¡å—åŒ–")

        return insights

    def _generate_performance_recommendations(
        self, metrics: Dict[str, Any]
    ) -> List[str]:
        """ç”Ÿæˆæ€§èƒ½å»ºè®®"""
        recommendations = []

        import_complexity = metrics.get("import_complexity", 0)
        if import_complexity > 200:
            recommendations.append("è€ƒè™‘ä¼˜åŒ–å¯¼å…¥ç»“æ„ï¼Œå‡å°‘ä¸å¿…è¦çš„ä¾èµ–")

        return recommendations

    def _calculate_quality_score(self, results: List[AnalysisResult]) -> float:
        """è®¡ç®—ç»¼åˆè´¨é‡è¯„åˆ†"""
        if not results:
            return 0.0

        successful_count = len([r for r in results if r.status == "SUCCESS"])
        total_count = len(results)

        base_score = (successful_count / total_count) * 100

        # æ ¹æ®å…·ä½“æŒ‡æ ‡è°ƒæ•´åˆ†æ•°
        for result in results:
            if result.analysis_type == "code_quality_analyzer":
                quality_score = result.metrics.get("quality_score", 0)
                base_score = (base_score + quality_score) / 2
                break

        return min(100.0, max(0.0, base_score))

    def _analyze_trends(self, results: List[AnalysisResult]) -> Dict[str, Any]:
        """åˆ†æè¶‹åŠ¿"""
        # ç®€åŒ–çš„è¶‹åŠ¿åˆ†æ
        return {
            "quality_trend": "stable",
            "debt_trend": "decreasing",
            "analysis_date": datetime.now().isoformat(),
        }

    def _extract_critical_findings(self, results: List[AnalysisResult]) -> List[str]:
        """æå–å…³é”®å‘ç°"""
        critical_findings = []

        for result in results:
            if result.status == "FAILED":
                critical_findings.append(f"{result.analysis_type}: åˆ†æå¤±è´¥")

            # æ£€æŸ¥æŠ€æœ¯å€ºåŠ¡
            if result.technical_debt:
                debt_count = result.technical_debt.get("total_count", 0)
                if debt_count > 10:
                    critical_findings.append(f"æŠ€æœ¯å€ºåŠ¡é¡¹è¿‡å¤š: {debt_count} é¡¹")

        return critical_findings

    def _update_analysis_history(self, report: ContinuousAnalysisReport):
        """æ›´æ–°åˆ†æå†å²"""
        self.analysis_history.append(asdict(report))

        # ä¿ç•™æœ€è¿‘100æ¬¡è®°å½•
        if len(self.analysis_history) > 100:
            self.analysis_history = self.analysis_history[-100:]

        self._save_history()

    def _print_analysis_summary(self, report: ContinuousAnalysisReport):
        """æ‰“å°åˆ†ææ‘˜è¦"""
        print("=" * 60)
        print("ğŸ“Š MCPæŒç»­åˆ†æç»“æœæ‘˜è¦")
        print("=" * 60)

        print(f"ğŸ“‹ æŠ¥å‘ŠID: {report.report_id}")
        print(f"ğŸ“‚ é¡¹ç›®è·¯å¾„: {report.project_path}")
        print(f"ğŸ”¢ åˆ†ææ€»æ•°: {report.total_analyses}")
        print(f"âœ… æˆåŠŸ: {report.successful_analyses}")
        print(f"âŒ å¤±è´¥: {report.failed_analyses}")
        print(f"ğŸ† ç»¼åˆè´¨é‡è¯„åˆ†: {report.overall_quality_score:.1f}/100")

        if report.critical_findings:
            print(f"\nğŸš¨ å…³é”®å‘ç°:")
            for finding in report.critical_findings:
                print(f"   â€¢ {finding}")

        print("=" * 60)

    def save_report(
        self, report: ContinuousAnalysisReport, output_path: Optional[str] = None
    ) -> str:
        """ä¿å­˜åˆ†ææŠ¥å‘Š"""
        if output_path is None:
            reports_dir = self.project_root / "quality" / "mcp-analysis" / "outputs"
            reports_dir.mkdir(parents=True, exist_ok=True)
            output_path = str(reports_dir / f"{report.report_id}.json")

        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(asdict(report), f, indent=2, ensure_ascii=False, default=str)

        print(f"ğŸ“„ MCPåˆ†ææŠ¥å‘Šå·²ä¿å­˜è‡³: {output_path}")
        return output_path


def main():
    """ä¸»å…¥å£å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="LifeSmart HACS MCPæŒç»­åˆ†æç³»ç»Ÿ")
    parser.add_argument("--project-root", type=str, default=".", help="é¡¹ç›®æ ¹ç›®å½•è·¯å¾„")
    parser.add_argument(
        "--analysis-types", nargs="*", default=None, help="æŒ‡å®šåˆ†æç±»å‹"
    )
    parser.add_argument(
        "--force-run", action="store_true", help="å¼ºåˆ¶è¿è¡Œï¼Œå¿½ç•¥æ—¶é—´é—´éš”é™åˆ¶"
    )
    parser.add_argument("--save-report", type=str, default=None, help="ä¿å­˜æŠ¥å‘Šçš„è·¯å¾„")

    args = parser.parse_args()

    # åˆå§‹åŒ–MCPåˆ†æå™¨
    project_root = pathlib.Path(args.project_root).resolve()
    analyzer = MCPContinuousAnalyzer(project_root)

    # è¿è¡Œåˆ†æ
    report = analyzer.run_continuous_analysis(
        analysis_types=args.analysis_types, force_run=args.force_run
    )

    # ä¿å­˜æŠ¥å‘Š
    analyzer.save_report(report, args.save_report)

    # æ ¹æ®è´¨é‡è¯„åˆ†ç¡®å®šé€€å‡ºç 
    exit_code = 0
    if report.overall_quality_score < 70:
        exit_code = 1
    elif len(report.critical_findings) > 0:
        exit_code = 1

    print(f"\nğŸš€ MCPæŒç»­åˆ†æå®Œæˆï¼Œé€€å‡ºç : {exit_code}")
    sys.exit(exit_code)


if __name__ == "__main__":
    main()
