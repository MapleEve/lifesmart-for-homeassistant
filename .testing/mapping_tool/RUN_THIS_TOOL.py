#!/usr/bin/env python3
"""
æ™ºèƒ½IOåˆ†é…å¯¹æ¯”åˆ†æå·¥å…· - å‡çº§ç‰ˆ
ä¸“æ³¨äºAIåˆ†ævsç°æœ‰åˆ†é…çš„å¯¹æ¯”ï¼Œæä¾›ç½®ä¿¡åº¦è¯„ä¼°å’Œå·®å¼‚æŠ¥å‘Š
ç§»é™¤æ— ç”¨çš„å¤šIOè®¾å¤‡å’ŒBitmaskæŠ¥å‘Šï¼Œå®ç°æ™ºèƒ½è¿‡æ»¤é¿å…æµªè´¹AI Token
ç”± @MapleEve åˆ›å»ºå’Œç»´æŠ¤

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. AI vs ç°æœ‰åˆ†é…å¯¹æ¯”ï¼šä¸“æ³¨äº493ä¸ªIOæ¥å£çš„åˆ†é…å·®å¼‚åˆ†æ
2. ç½®ä¿¡åº¦è¯„ä¼°ï¼šå¤šç»´åº¦ç½®ä¿¡åº¦æ¨¡å‹ï¼Œè‡ªåŠ¨è¿‡æ»¤100%åŒ¹é…è®¾å¤‡
3. å·®å¼‚èšç„¦æŠ¥å‘Šï¼šåªå…³æ³¨éœ€è¦äººå·¥å¹²é¢„çš„ä¸ä¸€è‡´è®¾å¤‡
4. æ™ºèƒ½Tokenç®¡ç†ï¼šé«˜ç½®ä¿¡åº¦åŒ¹é…è®¾å¤‡ä¸æ¶ˆè€—AIèµ„æº
"""

import json

# Add the custom component to path for importing const.py
import os
import sys
from datetime import datetime
from typing import Dict, Set, List, Any

sys.path.insert(
    0, os.path.join(os.path.dirname(__file__), "../../custom_components/lifesmart")
)

try:
    # Import the device mappings - é€‚é…å½“å‰æ¶æ„
    from core.config.device_specs import _RAW_DEVICE_DATA

    # é‡å‘½åä»¥ä¿æŒå…¼å®¹æ€§
    DEVICE_MAPPING = _RAW_DEVICE_DATA

    # Import utils modules for enhanced analysis
    from utils.strategies import EnhancedAnalysisEngine, EnhancedAnalysisResult
    from utils.io_logic_analyzer import PlatformAllocationValidator
    from utils.document_parser import DocumentParser
    from utils.core_utils import DeviceNameUtils, RegexCache
    from utils.regex_cache import enable_debug_mode, regex_performance_monitor
    from utils.memory_agent1 import MemoryAgent1, create_memory_agent1
    from utils.pure_ai_analyzer import (
        analyze_document_realtime,
        DocumentBasedComparisonAnalyzer,
    )

except ImportError as e:
    print(f"âš ï¸ Import warning: {e}")
    print("ğŸ¯ è¿è¡Œæ™ºèƒ½æ¨¡å¼ï¼šä¾èµ–Agentåˆ†æç»“æœï¼Œè·³è¿‡æœ¬åœ°æ¨¡å—å¯¼å…¥")

    # åˆ›å»ºå ä½ç±»å’Œå‡½æ•°ä»¥é¿å…é”™è¯¯
    class MockAnalysisResult:
        def __init__(self):
            pass

    class MockComparisonAnalyzer:
        def analyze_and_compare(self, existing_data):
            from datetime import datetime

            # ä»ç°æœ‰æ•°æ®ä¸­æå–è®¾å¤‡ä¿¡æ¯
            existing_devices = existing_data.get("devices", {})
            comparison_results = []

            print(f"ğŸ¯ MockComparisonAnalyzerå¤„ç† {len(existing_devices)} ä¸ªç°æœ‰è®¾å¤‡")

            # ä¸ºæ¯ä¸ªç°æœ‰è®¾å¤‡ç”Ÿæˆå¯¹æ¯”ç»“æœ
            for device_name, device_data in existing_devices.items():
                # å®‰å…¨åœ°è·å–å¹³å°ä¿¡æ¯
                platforms = []
                if isinstance(device_data, dict):
                    platforms_data = device_data.get("platforms", {})
                    if isinstance(platforms_data, dict):
                        platforms = list(platforms_data.keys())
                    elif isinstance(platforms_data, list):
                        platforms = platforms_data

                comparison_results.append(
                    {
                        "device_name": device_name,
                        "match_type": "ç°æœ‰ç‹¬æœ‰",
                        "confidence_score": 0.3,
                        "differences": ["è®¾å¤‡ä»…å­˜åœ¨äºç°æœ‰é…ç½®ä¸­"],
                        "existing_platforms": platforms,
                        "ai_platforms": [],
                    }
                )

            total_devices = len(comparison_results)
            print(f"   ç”Ÿæˆäº† {total_devices} ä¸ªè®¾å¤‡çš„å¯¹æ¯”ç»“æœ")

            return {
                "agent3_results": {
                    "comparison_results": comparison_results,
                    "overall_statistics": {
                        "perfect_match_rate": 0.0,
                        "total_devices": total_devices,
                        "match_distribution": {
                            "perfect_match": 0,
                            "partial_match": 0,
                            "platform_mismatch": 0,
                            "io_missing": 0,
                            "ai_only": 0,
                            "existing_only": total_devices,
                        },
                    },
                },
                "analysis_metadata": {
                    "tool": "Mock Fallback Analyzer (Fixed)",
                    "version": "1.1",
                    "timestamp": datetime.now().isoformat(),
                },
            }

    EnhancedAnalysisResult = MockAnalysisResult
    DocumentBasedComparisonAnalyzer = MockComparisonAnalyzer

    # ä¿®å¤ï¼šå³ä½¿å¯¼å…¥å¤±è´¥ä¹Ÿè¦åŠ è½½çœŸå®è®¾å¤‡æ•°æ®
    try:
        device_specs_path = os.path.join(
            os.path.dirname(__file__),
            "../../custom_components/lifesmart/core/config/device_specs.py",
        )

        print(f"ğŸ”„ å›é€€æ¨¡å¼ï¼šç›´æ¥ä»æ–‡ä»¶åŠ è½½è®¾å¤‡æ•°æ®")

        if os.path.exists(device_specs_path):
            with open(device_specs_path, "r", encoding="utf-8") as f:
                content = f.read()

            globals_dict = {}
            exec(content, globals_dict)
            DEVICE_MAPPING = globals_dict.get("_RAW_DEVICE_DATA", {})

            print(f"âœ… ç›´æ¥åŠ è½½æˆåŠŸ: {len(DEVICE_MAPPING)}ä¸ªè®¾å¤‡")
            if DEVICE_MAPPING:
                print(f"   å‰5ä¸ªè®¾å¤‡: {list(DEVICE_MAPPING.keys())[:5]}")
        else:
            print(f"âŒ è®¾å¤‡è§„æ ¼æ–‡ä»¶ä¸å­˜åœ¨: {device_specs_path}")
            DEVICE_MAPPING = {}

    except Exception as e:
        print(f"âŒ ç›´æ¥åŠ è½½è®¾å¤‡æ•°æ®å¤±è´¥: {e}")
        DEVICE_MAPPING = {}

    def enable_debug_mode():
        pass

    def regex_performance_monitor(func):
        return func

    def create_memory_agent1(supported_platforms=None, raw_data=None):
        # ä¿®å¤ï¼šä½¿ç”¨çœŸå®è®¾å¤‡æ•°æ®è€Œä¸æ˜¯ç©ºè¿­ä»£å™¨
        if not raw_data:
            raw_data = DEVICE_MAPPING

        class MockMemoryAgent1:
            def __init__(self):
                self.device_data = raw_data

            def get_existing_allocation_stream(self):
                # è¿”å›çœŸå®è®¾å¤‡æ•°æ®è€Œä¸æ˜¯ç©ºè¿­ä»£å™¨
                if self.device_data:
                    # é¦–å…ˆè¿”å›å…ƒæ•°æ®
                    yield {
                        "metadata": {
                            "total_devices": len(self.device_data),
                            "source": "direct_load",
                            "generation_time": datetime.now().strftime(
                                "%Y-%m-%d %H:%M:%S"
                            ),
                        }
                    }

                    # ç„¶åè¿”å›è®¾å¤‡æ•°æ®
                    for device_name, device_config in self.device_data.items():
                        platforms = []
                        ios = []
                        for key, value in device_config.items():
                            if key not in [
                                "name",
                                "description",
                                "versioned",
                                "dynamic",
                            ]:
                                platforms.append(key)
                                if isinstance(value, dict):
                                    ios.extend(list(value.keys()))

                        yield {
                            "device": {
                                "device_name": device_name,
                                "platforms": platforms,
                                "ios": [
                                    {"name": io, "platform": "unknown"} for io in ios
                                ],
                            }
                        }
                else:
                    return iter([])

            def get_performance_metrics(self):
                return {
                    "memory_usage": {"rss_mb": 50.0, "vms_mb": 100.0},
                    "cache_performance": {"hits": 10, "misses": 2, "hit_rate": 0.83},
                    "concurrency": {"active_requests": 0, "max_workers": 4},
                    "data_statistics": {
                        "processing_time": 0.1,
                        "total_devices": (
                            len(self.device_data) if self.device_data else 0
                        ),
                    },
                }

        return MockMemoryAgent1()


class SmartIOAllocationAnalyzer:
    """æ™ºèƒ½IOåˆ†é…å¯¹æ¯”åˆ†æå™¨ - ä¸“æ³¨å·®å¼‚è®¾å¤‡ï¼Œæ™ºèƒ½è¿‡æ»¤100%åŒ¹é…"""

    def __init__(self, enable_performance_monitoring: bool = False):
        """
        åˆå§‹åŒ–åˆ†æå™¨

        Args:
            enable_performance_monitoring: æ˜¯å¦å¯ç”¨æ€§èƒ½ç›‘æ§
        """
        # è¯»å–SUPPORTED_PLATFORMSé…ç½®
        self.supported_platforms = self._load_supported_platforms()

        try:
            self.document_parser = DocumentParser()
            # åˆ›å»ºå¢å¼ºç‰ˆåˆ†æå¼•æ“
            self.analysis_engine = EnhancedAnalysisEngine(self.supported_platforms)
        except:
            # æ™ºèƒ½æ¨¡å¼ï¼šä½¿ç”¨æ¨¡æ‹Ÿå¯¹è±¡
            print("ğŸ“ ä½¿ç”¨æ™ºèƒ½æ¨¡å¼ï¼šåŸºäºAgentåˆ†æç»“æœ")
            self.document_parser = None
            self.analysis_engine = None

        # æ™ºèƒ½è¿‡æ»¤é…ç½®
        self.confidence_threshold = 0.95  # é«˜ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œè¶…è¿‡æ­¤å€¼è‡ªåŠ¨è¿‡æ»¤
        self.filtered_devices = []  # è¢«è¿‡æ»¤çš„100%åŒ¹é…è®¾å¤‡
        self.focus_devices = []  # éœ€è¦å…³æ³¨çš„å·®å¼‚è®¾å¤‡

        # åˆå§‹åŒ–å†…å­˜æ¨¡å¼çš„Agent1
        self.memory_agent1 = None
        self._initialize_memory_agent1()

        if enable_performance_monitoring:
            enable_debug_mode()

    def _load_supported_platforms(self) -> Set[str]:
        """åŠ è½½å½“å‰æ”¯æŒçš„å¹³å°åˆ—è¡¨ï¼Œæ’é™¤è¢«æ³¨é‡Šçš„å¹³å°"""
        # è¯»å–const.pyæ–‡ä»¶å†…å®¹ - ä¿®æ­£è·¯å¾„è®¡ç®—
        const_file_path = os.path.join(
            os.path.dirname(os.path.dirname(os.path.dirname(__file__))),
            "custom_components/lifesmart/core/const.py",
        )

        active_platforms = set()
        commented_platforms = set()

        try:
            with open(const_file_path, "r", encoding="utf-8") as f:
                content = f.read()

            # æŸ¥æ‰¾SUPPORTED_PLATFORMSå®šä¹‰
            import re

            lines = content.split("\n")
            in_supported_platforms = False

            for line in lines:
                line_stripped = line.strip()

                if "SUPPORTED_PLATFORMS" in line_stripped and "{" in line_stripped:
                    in_supported_platforms = True
                    continue

                if in_supported_platforms:
                    if "}" in line_stripped:
                        break

                    # æ£€æŸ¥å¹³å°å®šä¹‰ - ä¿®å¤æ­£åˆ™è¡¨è¾¾å¼è½¬ä¹‰é—®é¢˜
                    if "Platform." in line_stripped:
                        platform_match = re.search(r"Platform\.(\w+)", line_stripped)
                        if platform_match:
                            platform_name = platform_match.group(1).lower()

                            if line_stripped.startswith("#"):
                                commented_platforms.add(platform_name)
                                print(f"ğŸ”‡ æ£€æµ‹åˆ°è¢«æ³¨é‡Šçš„å¹³å°: {platform_name}")
                            else:
                                active_platforms.add(platform_name)
                                print(f"âœ… æ£€æµ‹åˆ°æ´»è·ƒå¹³å°: {platform_name}")

            print(f"ğŸ“Š å¹³å°çŠ¶æ€ç»Ÿè®¡:")
            print(f"   æ´»è·ƒå¹³å°: {len(active_platforms)} ä¸ª")
            print(f"   è¢«æ³¨é‡Šå¹³å°: {len(commented_platforms)} ä¸ª")

        except Exception as e:
            print(f"âš ï¸ è¯»å–const.pyæ–‡ä»¶å¤±è´¥: {e}")
            # ä½¿ç”¨é»˜è®¤çš„17ä¸ªå¹³å°é…ç½®
            active_platforms = {
                "switch",
                "binary_sensor",
                "sensor",
                "cover",
                "light",
                "climate",
                "remote",
                "fan",
                "lock",
                "camera",
                "alarm_control_panel",
                "device_tracker",
                "media_player",
                "number",
                "select",
                "button",
                "text",
            }
            print(f"ğŸ“‹ ä½¿ç”¨é»˜è®¤å¹³å°é…ç½®: {len(active_platforms)} ä¸ªå¹³å°")

        return active_platforms

    def _initialize_memory_agent1(self):
        """åˆå§‹åŒ–å†…å­˜æ¨¡å¼çš„Agent1"""
        try:
            # åˆ›å»ºå†…å­˜æ¨¡å¼çš„Agent1
            self.memory_agent1 = create_memory_agent1(
                supported_platforms=self.supported_platforms, raw_data=DEVICE_MAPPING
            )
            print("âœ… å†…å­˜æ¨¡å¼Agent1åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸ å†…å­˜æ¨¡å¼Agent1åˆå§‹åŒ–å¤±è´¥: {e}")
            self.memory_agent1 = None

    @regex_performance_monitor
    def load_official_documentation(self, doc_path: str) -> Dict[str, List[str]]:
        """
        åŠ è½½å®˜æ–¹æ–‡æ¡£å¹¶æå–IOå£ä¿¡æ¯

        ä¿®å¤ï¼šè½¬æ¢æ ¼å¼ä»Dict[str, List[Dict]] åˆ° Dict[str, List[str]]

        Args:
            doc_path: å®˜æ–¹æ–‡æ¡£è·¯å¾„

        Returns:
            è®¾å¤‡ååˆ°IOå£ååˆ—è¡¨çš„æ˜ å°„ {device_name: [io1, io2, ...]}
        """
        # ä½¿ç”¨æ–‡æ¡£è§£æå™¨æå–åŸå§‹æ•°æ®
        raw_doc_data = self.document_parser.extract_device_ios_from_docs()

        # è½¬æ¢æ ¼å¼ï¼šæå–IOå£åç§°
        device_ios_map = {}
        for device_name, io_definitions in raw_doc_data.items():
            if io_definitions:
                # ä»IOå®šä¹‰ä¸­æå–IOå£åç§°
                io_names = []
                for io_def in io_definitions:
                    if isinstance(io_def, dict) and "name" in io_def:
                        io_names.append(io_def["name"])
                    elif isinstance(io_def, str):
                        io_names.append(io_def)
                device_ios_map[device_name] = io_names
            else:
                device_ios_map[device_name] = []

        print(f"ğŸ“‹ å®˜æ–¹æ–‡æ¡£æ•°æ®è½¬æ¢å®Œæˆ:")
        print(f"   æ‰¾åˆ°è®¾å¤‡: {len(device_ios_map)} ä¸ª")
        total_ios = sum(len(ios) for ios in device_ios_map.values())
        print(f"   æ€»IOå£æ•°: {total_ios} ä¸ª")

        # æ˜¾ç¤ºå‰å‡ ä¸ªè®¾å¤‡çš„IOå£ä¿¡æ¯ç”¨äºè°ƒè¯•
        for i, (device, ios) in enumerate(list(device_ios_map.items())[:3]):
            print(f"   ç¤ºä¾‹è®¾å¤‡ {device}: {ios}")
            if i >= 2:  # åªæ˜¾ç¤ºå‰3ä¸ª
                break

        return device_ios_map

    @regex_performance_monitor
    def prepare_device_mappings_from_real_data(self) -> Dict[str, Any]:
        """
        ä»çœŸå®çš„æ˜ å°„æ•°æ®å‡†å¤‡è®¾å¤‡æ˜ å°„

        Returns:
            æ•´åˆåçš„è®¾å¤‡æ˜ å°„æ•°æ®
        """
        combined_mappings = {}

        # å¤„ç†æ‰€æœ‰è®¾å¤‡æ˜ å°„
        for device_name, device_config in DEVICE_MAPPING.items():
            if self._is_valid_device_for_analysis(device_name):
                # æ£€æŸ¥è®¾å¤‡æ˜¯å¦ä¸ºç‰ˆæœ¬è®¾å¤‡
                if RegexCache.is_version_device(device_name):
                    combined_mappings[device_name] = {
                        "versioned": True,
                        **device_config,
                    }
                # æ£€æŸ¥è®¾å¤‡æ˜¯å¦ä¸ºåŠ¨æ€åˆ†ç±»è®¾å¤‡
                elif self._is_dynamic_classification_device(device_config):
                    combined_mappings[device_name] = {
                        "dynamic": True,
                        **device_config,
                    }
                else:
                    # æ ‡å‡†è®¾å¤‡
                    combined_mappings[device_name] = device_config

        return combined_mappings

    def _is_dynamic_classification_device(self, device_config: Dict[str, Any]) -> bool:
        """æ£€æŸ¥è®¾å¤‡æ˜¯å¦ä¸ºåŠ¨æ€åˆ†ç±»è®¾å¤‡"""
        if not isinstance(device_config, dict):
            return False

        # é€šè¿‡é…ç½®ç»“æ„åˆ¤æ–­
        dynamic_indicators = [
            "control_modes",
            "switch_mode",
            "climate_mode",
            "dynamic",
            "classification",
        ]

        return any(indicator in device_config for indicator in dynamic_indicators)

    def _is_valid_device_for_analysis(self, device_name: str) -> bool:
        """æ£€æŸ¥è®¾å¤‡æ˜¯å¦åº”è¯¥åŒ…å«åœ¨åˆ†æä¸­"""
        return DeviceNameUtils.is_valid_device_name(device_name)

    def _extract_ios_from_device_specs(
        self, device_specs_data: Dict[str, Any]
    ) -> Dict[str, List[str]]:
        """
        ä»device_specsçº¯æ•°æ®ä¸­æå–IOå£ä¿¡æ¯

        è¿™æ˜¯AIåˆ†æçš„åŸºå‡†æ•°æ®æºï¼Œæ¥è‡ªçº¯å‡€çš„è®¾å¤‡è§„æ ¼å®šä¹‰

        Args:
            device_specs_data: device_specs.pyä¸­çš„_RAW_DEVICE_DATA

        Returns:
            è®¾å¤‡ååˆ°IOå£åˆ—è¡¨çš„æ˜ å°„ {device_name: [io1, io2, ...]}
        """
        device_ios_map = {}

        for device_name, device_config in device_specs_data.items():
            if not isinstance(device_config, dict):
                continue

            ios = set()

            # éå†æ‰€æœ‰å¹³å°ç±»å‹ (switch, sensor, light, ç­‰)
            for platform_key, platform_config in device_config.items():
                if platform_key in ["name", "versioned", "dynamic"]:
                    continue

                if isinstance(platform_config, dict):
                    # æå–è¯¥å¹³å°ä¸‹çš„æ‰€æœ‰IOå£åç§°
                    ios.update(platform_config.keys())

            device_ios_map[device_name] = list(ios)

        return device_ios_map

    @regex_performance_monitor
    def perform_smart_comparison_analysis(self, doc_path: str) -> Dict[str, Any]:
        """
        æ‰§è¡Œæ™ºèƒ½IOåˆ†é…å¯¹æ¯”åˆ†æ - ä¸“æ³¨äºå·®å¼‚è®¾å¤‡

        Args:
            doc_path: å®˜æ–¹æ–‡æ¡£è·¯å¾„

        Returns:
            æ™ºèƒ½è¿‡æ»¤åçš„åˆ†æç»“æœå­—å…¸
        """
        print("ğŸš€ å¼€å§‹æ™ºèƒ½IOåˆ†é…å¯¹æ¯”åˆ†æ...")

        # 1. ä½¿ç”¨å†…å­˜æ¨¡å¼Agent1çš„åˆ†æç»“æœ - ç°æœ‰åˆ†é…æ•°æ®
        print("ğŸ“š é˜¶æ®µ1: ä½¿ç”¨å†…å­˜æ¨¡å¼Agent1åŠ è½½ç°æœ‰åˆ†é…æ•°æ®...")

        if self.memory_agent1:
            # ä½¿ç”¨å†…å­˜æ¨¡å¼Agent1
            print("ğŸš€ ä½¿ç”¨å†…å­˜æ¨¡å¼Agent1 - é›¶æ–‡ä»¶ä¾èµ–")
            try:
                # è·å–æµå¼æ•°æ®å¹¶æ„å»ºç»“æœ
                devices = {}
                metadata = None

                for stream_item in self.memory_agent1.get_existing_allocation_stream():
                    if "metadata" in stream_item:
                        metadata = stream_item["metadata"]
                        print(f"ğŸ“Š å†…å­˜Agent1å…ƒæ•°æ®: {metadata['total_devices']}ä¸ªè®¾å¤‡")
                    elif "device" in stream_item:
                        device_data = stream_item["device"]
                        devices[device_data["device_name"]] = device_data

                existing_data = {
                    "metadata": metadata,
                    "devices": devices,
                    "source": "memory_agent1",
                }

                print(f"âœ… å†…å­˜Agent1åŠ è½½å®Œæˆ: {len(devices)}ä¸ªè®¾å¤‡ï¼Œé›¶æ–‡ä»¶I/O")

                # æ˜¾ç¤ºæ€§èƒ½æŒ‡æ ‡
                metrics = self.memory_agent1.get_performance_metrics()
                print(
                    f"ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡: å†…å­˜ä½¿ç”¨{metrics['memory_usage']['rss_mb']:.1f}MB, "
                    f"ç¼“å­˜å‘½ä¸­ç‡{metrics['cache_performance']['hit_rate']:.2%}"
                )

            except Exception as e:
                print(f"âŒ å†…å­˜Agent1å¤„ç†å¤±è´¥: {e}ï¼Œå›é€€åˆ°ä¼ ç»Ÿæ¨¡å¼")
                self.memory_agent1 = None

        if not self.memory_agent1:
            # å›é€€åˆ°ä¼ ç»Ÿæ–‡ä»¶æ¨¡å¼
            print("ğŸ“ å›é€€åˆ°ä¼ ç»Ÿæ–‡ä»¶æ¨¡å¼")
            existing_allocation_file = (
                "/Volumes/LocalRAW/lifesmart-HACS-for-hass/tmp/"
                "existing_io_allocations.json"  # ä½¿ç”¨åŒ…å«å®Œæ•´123ä¸ªè®¾å¤‡çš„æ–‡ä»¶
            )
            if os.path.exists(existing_allocation_file):
                with open(existing_allocation_file, "r", encoding="utf-8") as f:
                    raw_data = json.load(f)

                # ä¿®å¤ï¼šæ£€æŸ¥å®é™…çš„æ•°æ®ç»“æ„
                if "devices" in raw_data:
                    devices_data = raw_data["devices"]
                elif "device_allocations" in raw_data:
                    devices_data = raw_data["device_allocations"]
                    print(f"ğŸ“ æ³¨æ„ï¼šä½¿ç”¨device_allocationsé”®è·å–è®¾å¤‡æ•°æ®")
                elif "device_sample" in raw_data:
                    devices_data = raw_data["device_sample"]
                    print(f"ğŸ“ æ³¨æ„ï¼šä½¿ç”¨device_sampleé”®è·å–è®¾å¤‡æ•°æ®")
                else:
                    # å°è¯•æ‰¾åˆ°åŒ…å«è®¾å¤‡æ•°æ®çš„é”®
                    devices_data = {}
                    for k, v in raw_data.items():
                        if isinstance(v, dict) and any(
                            device_name.startswith("SL_") for device_name in v.keys()
                        ):
                            devices_data = v
                            print(f"ğŸ“ è‡ªåŠ¨æ£€æµ‹åˆ°è®¾å¤‡æ•°æ®åœ¨é”®'{k}'ä¸­")
                            break

                # è½¬æ¢æ•°æ®æ ¼å¼ä»¥åŒ¹é…æœŸæœ›çš„ç»“æ„
                existing_data = {
                    "metadata": raw_data.get(
                        "metadata", {"total_devices": len(devices_data)}
                    ),
                    "devices": {},
                }

                # è½¬æ¢è®¾å¤‡æ•°æ®æ ¼å¼ - æ”¯æŒä¸¤ç§æ ¼å¼
                for device_name, device_info in devices_data.items():
                    if "platforms" in device_info:
                        # æ ¼å¼1ï¼šdevice_sampleæ ¼å¼ï¼š{platforms: {switch: ["O"]}}
                        platforms = list(device_info.get("platforms", {}).keys())
                        ios = []

                        for platform, io_list in device_info.get(
                            "platforms", {}
                        ).items():
                            for io_name in io_list:
                                ios.append({"name": io_name, "platform": platform})
                    else:
                        # æ ¼å¼2ï¼šdevice_allocationsæ ¼å¼ï¼š{switch: ["O"], sensor: ["P1"]}
                        platforms = list(device_info.keys())
                        ios = []

                        for platform, io_list in device_info.items():
                            for io_name in io_list:
                                ios.append({"name": io_name, "platform": platform})

                    existing_data["devices"][device_name] = {
                        "name": device_info.get("name", device_name),
                        "platforms": platforms,
                        "ios": ios,
                    }

                print(f"âœ… åŠ è½½äº†ç°æœ‰åˆ†é…æ•°æ®: {len(existing_data['devices'])}ä¸ªè®¾å¤‡")
            else:
                # å¦‚æœAgent1ç»“æœä¸å­˜åœ¨ï¼Œä½¿ç”¨åŸæœ‰é€»è¾‘
                device_specs_data = _RAW_DEVICE_DATA
                current_mapping_config = self.prepare_device_mappings_from_real_data()
                existing_data = {"devices": current_mapping_config}
                print(f"âœ… å‡†å¤‡äº†ç°æœ‰æ˜ å°„é…ç½®: {len(current_mapping_config)}ä¸ªè®¾å¤‡")

        # 2. ä½¿ç”¨Agent2çš„åˆ†æç»“æœ - AIåˆ†é…å»ºè®®
        print("ğŸ§  é˜¶æ®µ2: åŠ è½½AIåˆ†é…å»ºè®®...")
        ai_allocation_file = "independent_ai_analysis.json"
        if os.path.exists(ai_allocation_file):
            with open(ai_allocation_file, "r", encoding="utf-8") as f:
                ai_data = json.load(f)
            # è®¡ç®—æ€»è®¾å¤‡æ•°ï¼ˆä»æ‰€æœ‰åˆ†ç±»ä¸­ï¼‰
            total_devices = sum(len(devices) for devices in ai_data.values())
            print(f"âœ… åŠ è½½äº†AIåˆ†æå»ºè®®: {total_devices}ä¸ªè®¾å¤‡")
        else:
            # å¦‚æœAgent2ç»“æœä¸å­˜åœ¨ï¼Œè¿›è¡ŒåŸºç¡€AIåˆ†æ
            if self.document_parser:
                raw_doc_data = self.document_parser.extract_device_ios_from_docs()
            else:
                raw_doc_data = {}
            ai_data = self._perform_basic_ai_analysis(raw_doc_data, existing_data)
            print(f"âœ… å®ŒæˆåŸºç¡€AIåˆ†æ")

        # 3. æ‰§è¡Œå®æ—¶NLPåˆ†æï¼ˆé›¶æ–‡ä»¶ä¾èµ–ï¼‰
        print("âš–ï¸ é˜¶æ®µ3: æ‰§è¡Œå®æ—¶NLPåˆ†æï¼ˆé›¶æ–‡ä»¶ä¾èµ–ï¼‰...")
        try:
            # ä½¿ç”¨å®æ—¶æ–‡æ¡£è§£æå’ŒNLPåˆ†æå™¨ï¼ˆç›´æ¥åˆ†æï¼Œæ— éœ€é¢„è®¡ç®—æ–‡ä»¶ï¼‰
            print("ğŸ“– æ­£åœ¨åŸºäºå®˜æ–¹æ–‡æ¡£æ‰§è¡Œå®æ—¶NLPåˆ†æ...")

            # åˆ›å»ºå®æ—¶NLPåˆ†æå™¨ - å¼ºåˆ¶ä½¿ç”¨çœŸå®åˆ†æå™¨
            try:
                from utils.pure_ai_analyzer import (
                    DocumentBasedComparisonAnalyzer as RealAnalyzer,
                )

                nlp_analyzer = RealAnalyzer()
                print("âœ… æˆåŠŸåˆ›å»ºçœŸå®çš„DocumentBasedComparisonAnalyzer")
            except ImportError:
                print("âŒ æ— æ³•å¯¼å…¥çœŸå®çš„DocumentBasedComparisonAnalyzerï¼Œä½¿ç”¨Mockç‰ˆæœ¬")
                nlp_analyzer = DocumentBasedComparisonAnalyzer()

            # æ‰§è¡Œå®æ—¶åˆ†æå’Œå¯¹æ¯”
            print(
                f"ğŸ” è°ƒè¯•ä¿¡æ¯: existing_dataåŒ…å« {len(existing_data.get('devices', {}))} ä¸ªè®¾å¤‡"
            )
            print(f"   å‰3ä¸ªè®¾å¤‡: {list(existing_data.get('devices', {}).keys())[:3]}")

            print("ğŸš€ å¼€å§‹è°ƒç”¨nlp_analyzer.analyze_and_compare...")
            comparison_data = nlp_analyzer.analyze_and_compare(existing_data)
            print("âœ… nlp_analyzer.analyze_and_compareè°ƒç”¨å®Œæˆ")

            # è·å–åˆ†æç»“æœç»Ÿè®¡
            agent3_results = comparison_data.get("agent3_results", {})
            overall_stats = agent3_results.get("overall_statistics", {})
            match_rate = overall_stats.get("perfect_match_rate", 0)
            total_devices = overall_stats.get("total_devices", 0)

            print(
                f"âœ… å®æ—¶NLPåˆ†æå®Œæˆ: åˆ†æ{total_devices}ä¸ªè®¾å¤‡ï¼Œå®Œç¾åŒ¹é…åº¦{match_rate}%"
            )
            print(f"ğŸ“Š å®æ—¶åˆ†æä¼˜åŠ¿: æ— éœ€é¢„è®¡ç®—æ–‡ä»¶ï¼Œç›´æ¥åŸºäºæœ€æ–°å®˜æ–¹æ–‡æ¡£")

        except Exception as e:
            print(f"âŒ å®æ—¶NLPåˆ†æå¤±è´¥ï¼Œè¯¦ç»†é”™è¯¯: {e}")
            import traceback

            print(f"ğŸ“ é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            print(f"âš ï¸ ä½¿ç”¨åŸºç¡€å¯¹æ¯”åˆ†æä½œä¸ºå›é€€...")
            comparison_data = self._perform_basic_comparison(existing_data, ai_data)
            print("âœ… å®ŒæˆåŸºç¡€å¯¹æ¯”åˆ†æï¼ˆå›é€€æ¨¡å¼ï¼‰")

        # 4. æ™ºèƒ½è¿‡æ»¤ï¼šç§»é™¤100%åŒ¹é…è®¾å¤‡ï¼Œèšç„¦å·®å¼‚è®¾å¤‡
        print("ğŸ¯ é˜¶æ®µ4: æ‰§è¡Œæ™ºèƒ½è¿‡æ»¤...")
        filtered_results = self._apply_smart_filtering(comparison_data)
        print(
            f"âœ… æ™ºèƒ½è¿‡æ»¤å®Œæˆ: {len(self.filtered_devices)}ä¸ªè®¾å¤‡è¢«è¿‡æ»¤ï¼Œ{len(self.focus_devices)}ä¸ªè®¾å¤‡éœ€è¦å…³æ³¨"
        )

        # 5. ç”Ÿæˆèšç„¦äºå·®å¼‚çš„æŠ¥å‘Š
        print("ğŸ“Š é˜¶æ®µ5: ç”Ÿæˆå·®å¼‚èšç„¦æŠ¥å‘Š...")
        smart_report = self._generate_smart_report(
            filtered_results, existing_data, ai_data
        )

        # 6. æ·»åŠ å†…å­˜Agent1çš„æ€§èƒ½ç»Ÿè®¡åˆ°æŠ¥å‘Š
        if self.memory_agent1:
            print("ğŸ“Š é˜¶æ®µ6: æ·»åŠ å†…å­˜æ¨¡å¼æ€§èƒ½ç»Ÿè®¡...")
            performance_metrics = self.memory_agent1.get_performance_metrics()
            smart_report["å†…å­˜æ¨¡å¼æ€§èƒ½"] = {
                "Agent1ç±»å‹": "å†…å­˜æ¨¡å¼ (é›¶æ–‡ä»¶ä¾èµ–)",
                "å†…å­˜ä½¿ç”¨": f"{performance_metrics['memory_usage']['rss_mb']:.1f}MB",
                "ç¼“å­˜å‘½ä¸­ç‡": f"{performance_metrics['cache_performance']['hit_rate']:.2%}",
                "å¹¶å‘è¯·æ±‚": performance_metrics["concurrency"]["active_requests"],
                "æ•°æ®å¤„ç†æ—¶é—´": f"{performance_metrics['data_statistics']['processing_time']:.2f}ç§’",
                "ä¼˜åŠ¿": [
                    "ğŸš€ é›¶æ–‡ä»¶I/Oæ“ä½œ",
                    "ğŸ’° æ”¯æŒå¹¶å‘è®¿é—®",
                    "âš¡ å†…å­˜ç¼“å­˜åŠ é€Ÿ",
                    "ğŸ”„ æµå¼æ•°æ®å¤„ç†",
                ],
            }
            print("âœ… å†…å­˜æ¨¡å¼æ€§èƒ½ç»Ÿè®¡å·²æ·»åŠ ")

        print("âœ… æ™ºèƒ½åˆ†æå®Œæˆï¼")
        return smart_report

    def _perform_basic_ai_analysis(
        self, raw_doc_data: Dict, existing_data: Dict
    ) -> Dict[str, Any]:
        """æ‰§è¡ŒåŸºç¡€AIåˆ†æï¼Œå½“Agent2ç»“æœä¸å­˜åœ¨æ—¶ä½¿ç”¨"""
        print("âš ï¸ Agent2ç»“æœç¼ºå¤±ï¼Œä½¿ç”¨åŸºç¡€æ¨¡å¼")
        # ç®€åŒ–çš„AIåˆ†æé€»è¾‘
        return {
            "device_allocations": {},
            "analysis_summary": {"analyzed_devices": 0, "confidence_scores": []},
        }

    def _perform_basic_comparison(
        self, existing_data: Dict, ai_data: Dict
    ) -> Dict[str, Any]:
        """æ‰§è¡ŒåŸºç¡€å¯¹æ¯”åˆ†æï¼Œå½“å®æ—¶NLPåˆ†æå¤±è´¥æ—¶ä½¿ç”¨"""
        print("âš ï¸ å®æ—¶NLPåˆ†æå¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€æ¨¡å¼")
        return {
            "agent3_results": {
                "comparison_results": [],
                "overall_statistics": {"perfect_match_rate": 0, "total_devices": 0},
            },
            "analysis_metadata": {
                "tool": "Basic Fallback Analyzer",
                "version": "1.0",
                "timestamp": datetime.now().isoformat(),
            },
        }

    def prepare_device_mappings_from_real_data(self) -> Dict[str, Any]:
        """å¤‡ç”¨æ–¹æ³•ï¼šå‡†å¤‡è®¾å¤‡æ˜ å°„æ•°æ®"""
        print("âš ï¸ ä½¿ç”¨ç©ºçš„è®¾å¤‡æ˜ å°„æ•°æ®")
        return {}

    def load_official_documentation(self, doc_path: str) -> Dict[str, List[str]]:
        """å¤‡ç”¨æ–¹æ³•ï¼šåŠ è½½å®˜æ–¹æ–‡æ¡£"""
        print("âš ï¸ è·³è¿‡å®˜æ–¹æ–‡æ¡£åŠ è½½")
        return {}

    def _apply_smart_filtering(self, comparison_data: Dict) -> Dict[str, Any]:
        """
        åº”ç”¨æ™ºèƒ½è¿‡æ»¤ï¼šç§»é™¤100%åŒ¹é…è®¾å¤‡ï¼Œèšç„¦å·®å¼‚è®¾å¤‡

        Args:
            comparison_data: å¯¹æ¯”åˆ†ææ•°æ®

        Returns:
            è¿‡æ»¤åçš„ç»“æœæ•°æ®
        """
        # ä¿®å¤ï¼šæ­£ç¡®è®¿é—®Agent3çš„comparison_resultsæ•°æ®
        agent3_results = comparison_data.get("agent3_results", {})
        comparison_results = agent3_results.get("comparison_results", [])

        print(f"ğŸ” æ™ºèƒ½è¿‡æ»¤åˆ†æ: å¤„ç† {len(comparison_results)} ä¸ªè®¾å¤‡")

        for device_analysis in comparison_results:
            device_name = device_analysis.get("device_name", "æœªçŸ¥è®¾å¤‡")
            confidence_score = device_analysis.get("confidence_score", 0.0)
            match_type = device_analysis.get("match_type", "unknown")

            print(
                f"  åˆ†æè®¾å¤‡: {device_name}, ç±»å‹: {match_type}, ç½®ä¿¡åº¦: {confidence_score}"
            )

            if match_type == "å®Œå…¨åŒ¹é…":
                # æ‰€æœ‰å®Œå…¨åŒ¹é…è®¾å¤‡éƒ½è¿‡æ»¤æ‰ï¼Œä¸ç®¡ç½®ä¿¡åº¦å¤šå°‘
                self.filtered_devices.append(
                    {
                        "device_name": device_name,
                        "confidence_score": confidence_score,
                        "match_type": match_type,
                        "reason": "å®Œå…¨åŒ¹é…è®¾å¤‡ï¼Œæ— éœ€åœ¨æŠ¥å‘Šä¸­æ˜¾ç¤º",
                    }
                )
            else:
                # éœ€è¦å…³æ³¨çš„å·®å¼‚è®¾å¤‡
                self.focus_devices.append(
                    {
                        "device_name": device_name,
                        "confidence_score": confidence_score,
                        "match_type": match_type,
                        "priority": self._calculate_priority(
                            confidence_score, match_type
                        ),
                        "analysis_details": device_analysis,
                    }
                )

        # æŒ‰ä¼˜å…ˆçº§æ’åºéœ€è¦å…³æ³¨çš„è®¾å¤‡
        self.focus_devices.sort(key=lambda x: x["priority"], reverse=True)

        print(
            f"âœ… æ™ºèƒ½è¿‡æ»¤å®Œæˆ: {len(self.filtered_devices)}ä¸ªè®¾å¤‡è¢«è¿‡æ»¤ï¼Œ{len(self.focus_devices)}ä¸ªè®¾å¤‡éœ€è¦å…³æ³¨"
        )

        return {
            "filtered_count": len(self.filtered_devices),
            "focus_count": len(self.focus_devices),
            "filtered_devices": self.filtered_devices,
            "focus_devices": self.focus_devices,
        }

    def _calculate_priority(self, confidence_score: float, match_type: str) -> int:
        """
        è®¡ç®—è®¾å¤‡ä¼˜å…ˆçº§åˆ†æ•°ï¼ˆè¶Šé«˜è¶Šéœ€è¦å…³æ³¨ï¼‰
        æ›´æ–°ä»¥å¤„ç†Agent3çš„å®é™…åŒ¹é…ç±»å‹

        Args:
            confidence_score: ç½®ä¿¡åº¦åˆ†æ•°
            match_type: Agent3çš„åŒ¹é…ç±»å‹

        Returns:
            ä¼˜å…ˆçº§åˆ†æ•° (0-100)
        """
        base_priority = 0

        # æ ¹æ®Agent3çš„å®é™…åŒ¹é…ç±»å‹ç¡®å®šåŸºç¡€ä¼˜å…ˆçº§
        if match_type == "å¹³å°ä¸åŒ¹é…":
            base_priority = 95  # æœ€é«˜ä¼˜å…ˆçº§
        elif match_type == "æ˜¾è‘—å·®å¼‚":
            base_priority = 85
        elif match_type == "éƒ¨åˆ†åŒ¹é…":
            base_priority = 60
        elif match_type == "ç°æœ‰ç‹¬æœ‰":
            base_priority = 30
        elif match_type == "å®Œå…¨åŒ¹é…":
            base_priority = 10  # æœ€ä½ä¼˜å…ˆçº§
        else:
            base_priority = 50  # æœªçŸ¥ç±»å‹çš„ä¸­ç­‰ä¼˜å…ˆçº§

        # æ ¹æ®ç½®ä¿¡åº¦è°ƒæ•´ä¼˜å…ˆçº§ (ç½®ä¿¡åº¦è¶Šä½ï¼Œä¼˜å…ˆçº§è¶Šé«˜)
        confidence_adjustment = int((1.0 - confidence_score) * 20)

        final_priority = min(100, base_priority + confidence_adjustment)
        return final_priority

    def _generate_mismatch_reason(self, analysis_details: Dict) -> str:
        """
        ç”Ÿæˆä¸åŒ¹é…çš„å…·ä½“åŸå› è¯´æ˜

        Args:
            analysis_details: åˆ†æè¯¦æƒ…å­—å…¸

        Returns:
            ä¸åŒ¹é…åŸå› çš„è¯¦ç»†è¯´æ˜
        """
        existing_platforms = set(analysis_details.get("existing_platforms", []))
        ai_platforms = set(analysis_details.get("ai_platforms", []))
        differences = analysis_details.get("differences", [])

        if not existing_platforms and ai_platforms:
            return f"è®¾å¤‡ä»…åœ¨AIåˆ†æä¸­å­˜åœ¨ï¼Œå»ºè®®æ·»åŠ åˆ°ç°æœ‰é…ç½®ä¸­ã€‚AIæ¨èå¹³å°ï¼š{', '.join(ai_platforms)}"
        elif existing_platforms and not ai_platforms:
            return f"è®¾å¤‡ä»…åœ¨ç°æœ‰é…ç½®ä¸­å­˜åœ¨ï¼Œå¯èƒ½ä¸ºå·²åºŸå¼ƒæˆ–ç‰¹æ®Šç”¨é€”è®¾å¤‡ã€‚ç°æœ‰å¹³å°ï¼š{', '.join(existing_platforms)}"
        elif not existing_platforms & ai_platforms:
            return f"å¹³å°å®Œå…¨ä¸åŒï¼šç°æœ‰é…ç½®ä½¿ç”¨{', '.join(existing_platforms)}ï¼ŒAIåˆ†æå»ºè®®ä½¿ç”¨{', '.join(ai_platforms)}ã€‚å¯èƒ½åŸå› ï¼šè®¾å¤‡åŠŸèƒ½é‡æ–°åˆ†ç±»æˆ–IOå£ç”¨é€”å˜æ›´ã€‚"
        else:
            common = existing_platforms & ai_platforms
            existing_only = existing_platforms - ai_platforms
            ai_only = ai_platforms - existing_platforms
            reason_parts = []

            if common:
                reason_parts.append(f"å…±åŒå¹³å°ï¼š{', '.join(common)}")
            if existing_only:
                reason_parts.append(f"ç°æœ‰ç‹¬æœ‰ï¼š{', '.join(existing_only)}")
            if ai_only:
                reason_parts.append(f"AIå»ºè®®ç‹¬æœ‰ï¼š{', '.join(ai_only)}")

            reason = "ï¼›".join(reason_parts)

            # æ·»åŠ å…·ä½“å·®å¼‚ä¿¡æ¯
            if differences:
                reason += f"ã€‚è¯¦ç»†å·®å¼‚ï¼š{'; '.join(differences[:2])}"  # åªæ˜¾ç¤ºå‰2ä¸ªå·®å¼‚

            return reason

    def _generate_smart_report(
        self, filtered_results: Dict, existing_data: Dict, ai_data: Dict
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆæ™ºèƒ½èšç„¦æŠ¥å‘Š - ç§»é™¤æ— ç”¨ä¿¡æ¯ï¼Œä¸“æ³¨å·®å¼‚è®¾å¤‡

        Args:
            filtered_results: æ™ºèƒ½è¿‡æ»¤ç»“æœ
            existing_data: ç°æœ‰åˆ†é…æ•°æ®
            ai_data: AIåˆ†ææ•°æ®

        Returns:
            æ™ºèƒ½æŠ¥å‘Šå­—å…¸
        """
        focus_devices = filtered_results.get("focus_devices", [])
        filtered_devices = filtered_results.get("filtered_devices", [])

        # è®¡ç®—å¤„ç†æ•ˆç‡ç»Ÿè®¡
        total_devices = len(focus_devices) + len(filtered_devices)
        processing_efficiency = (
            (len(filtered_devices) / total_devices * 100) if total_devices > 0 else 0
        )

        # åˆ†ç±»éœ€è¦å…³æ³¨çš„è®¾å¤‡
        high_priority = [d for d in focus_devices if d["priority"] >= 80]
        medium_priority = [d for d in focus_devices if 50 <= d["priority"] < 80]
        low_priority = [d for d in focus_devices if d["priority"] < 50]

        smart_report = {
            "åˆ†ææ¦‚è§ˆ": {
                "ç”Ÿæˆæ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "å·¥å…·ç‰ˆæœ¬": "RUN_THIS_TOOL.py v4.3 (å¢å¼ºè¯¦æƒ…ç‰ˆ)",
                "åˆ†ææ¨¡å¼": "æ™ºèƒ½IOåˆ†é…å¯¹æ¯” (ä¸“æ³¨å·®å¼‚è®¾å¤‡)",
                "æ€»è®¾å¤‡æ•°": total_devices,
                "éœ€è¦å…³æ³¨è®¾å¤‡æ•°": len(focus_devices),
                "å·²è¿‡æ»¤è®¾å¤‡æ•°": len(filtered_devices),
                "å¤„ç†æ•ˆç‡": f"{processing_efficiency:.1f}%",
                "ç½®ä¿¡åº¦é˜ˆå€¼": self.confidence_threshold,
            },
            "æ™ºèƒ½è¿‡æ»¤ç»“æœ": {
                "è¿‡æ»¤ç­–ç•¥": "è‡ªåŠ¨è¿‡æ»¤100%åŒ¹é…ä¸”é«˜ç½®ä¿¡åº¦è®¾å¤‡",
                "é«˜åŒ¹é…åº¦è®¾å¤‡": len(filtered_devices),
                "éœ€è¦å…³æ³¨è®¾å¤‡": len(focus_devices),
                "è¿‡æ»¤è®¾å¤‡åˆ—è¡¨": [
                    d["device_name"] for d in filtered_devices[:10]
                ],  # åªæ˜¾ç¤ºå‰10ä¸ª
            },
            "å·®å¼‚è®¾å¤‡åˆ†æ": {
                "é«˜ä¼˜å…ˆçº§è®¾å¤‡": {
                    "æ•°é‡": len(high_priority),
                    "è¯´æ˜": "éœ€è¦ç«‹å³å…³æ³¨çš„å…³é”®å·®å¼‚",
                    "è®¾å¤‡åˆ—è¡¨": [
                        {
                            "è®¾å¤‡å": d["device_name"],
                            "ç½®ä¿¡åº¦": d["confidence_score"],
                            "ç±»å‹": d["match_type"],
                            "ç°æœ‰å¹³å°é…ç½®": d["analysis_details"].get(
                                "existing_platforms", []
                            ),
                            "AIæ¨èå¹³å°é…ç½®": d["analysis_details"].get(
                                "ai_platforms", []
                            ),
                            "ç°æœ‰IOå£": d["analysis_details"].get("existing_ios", []),
                            "AIæ¨èIOå£": d["analysis_details"].get("ai_ios", []),
                            "å·®å¼‚è¯¦æƒ…": d["analysis_details"].get("differences", []),
                            "ä¸åŒ¹é…åŸå› ": self._generate_mismatch_reason(
                                d["analysis_details"]
                            ),
                        }
                        for d in high_priority  # æ˜¾ç¤ºæ‰€æœ‰é«˜ä¼˜å…ˆçº§è®¾å¤‡
                    ],
                },
                "ä¸­ä¼˜å…ˆçº§è®¾å¤‡": {
                    "æ•°é‡": len(medium_priority),
                    "è¯´æ˜": "å»ºè®®ä¼˜åŒ–çš„ä¸­ç­‰å·®å¼‚",
                    "è®¾å¤‡åˆ—è¡¨": [
                        {
                            "è®¾å¤‡å": d["device_name"],
                            "ç½®ä¿¡åº¦": d["confidence_score"],
                            "ç±»å‹": d["match_type"],
                            "ç°æœ‰å¹³å°é…ç½®": d["analysis_details"].get(
                                "existing_platforms", []
                            ),
                            "AIæ¨èå¹³å°é…ç½®": d["analysis_details"].get(
                                "ai_platforms", []
                            ),
                            "ç°æœ‰IOå£": d["analysis_details"].get("existing_ios", []),
                            "AIæ¨èIOå£": d["analysis_details"].get("ai_ios", []),
                            "å·®å¼‚è¯¦æƒ…": d["analysis_details"].get("differences", []),
                            "ä¸åŒ¹é…åŸå› ": self._generate_mismatch_reason(
                                d["analysis_details"]
                            ),
                        }
                        for d in medium_priority  # æ˜¾ç¤ºæ‰€æœ‰ä¸­ä¼˜å…ˆçº§è®¾å¤‡
                    ],
                },
                "ä½ä¼˜å…ˆçº§è®¾å¤‡": {
                    "æ•°é‡": len(low_priority),
                    "è¯´æ˜": "å¯é€‰æ”¹è¿›çš„è½»å¾®å·®å¼‚",
                    "è®¾å¤‡åˆ—è¡¨": [
                        {
                            "è®¾å¤‡å": d["device_name"],
                            "ç½®ä¿¡åº¦": d["confidence_score"],
                            "ç±»å‹": d["match_type"],
                            "ç°æœ‰å¹³å°é…ç½®": d["analysis_details"].get(
                                "existing_platforms", []
                            ),
                            "AIæ¨èå¹³å°é…ç½®": d["analysis_details"].get(
                                "ai_platforms", []
                            ),
                            "ç°æœ‰IOå£": d["analysis_details"].get("existing_ios", []),
                            "AIæ¨èIOå£": d["analysis_details"].get("ai_ios", []),
                            "å·®å¼‚è¯¦æƒ…": d["analysis_details"].get("differences", []),
                            "ä¸åŒ¹é…åŸå› ": self._generate_mismatch_reason(
                                d["analysis_details"]
                            ),
                        }
                        for d in low_priority  # æ˜¾ç¤ºæ‰€æœ‰ä½ä¼˜å…ˆçº§è®¾å¤‡
                    ],
                },
            },
            "æ ¸å¿ƒå‘ç°": self._extract_key_insights(focus_devices),
            "è¡ŒåŠ¨å»ºè®®": self._generate_actionable_recommendations(
                high_priority, medium_priority
            ),
            "åŠŸèƒ½çŠ¶æ€": {
                "æ™ºèƒ½è¿‡æ»¤": "âœ… å·²å¯ç”¨",
                "å·®å¼‚èšç„¦": "âœ… å·²å¯ç”¨",
                "TokenèŠ‚çœ": "âœ… å·²å¯ç”¨",
                "ç½®ä¿¡åº¦è¯„ä¼°": "âœ… å·²å¯ç”¨",
                "å¤šAgentåä½œ": "âœ… å·²å¯ç”¨",
                "æ— ç”¨æŠ¥å‘Šç§»é™¤": "âœ… å¤šIOè®¾å¤‡å’ŒBitmaskæŠ¥å‘Šå·²ç§»é™¤",
            },
        }

        return smart_report

    def _extract_key_insights(self, focus_devices: List[Dict]) -> Dict[str, Any]:
        """ä»å…³æ³¨è®¾å¤‡ä¸­æå–å…³é”®æ´å¯Ÿ"""
        if not focus_devices:
            return {"çŠ¶æ€": "æ‰€æœ‰è®¾å¤‡åŒ¹é…åº¦è‰¯å¥½ï¼Œæ— éœ€ç‰¹æ®Šå…³æ³¨"}

        # ç»Ÿè®¡åŒ¹é…ç±»å‹åˆ†å¸ƒ
        match_type_counts = {}
        confidence_scores = []

        for device in focus_devices:
            match_type = device["match_type"]
            match_type_counts[match_type] = match_type_counts.get(match_type, 0) + 1
            confidence_scores.append(device["confidence_score"])

        avg_confidence = (
            sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0
        )

        return {
            "å·®å¼‚ç±»å‹åˆ†å¸ƒ": match_type_counts,
            "å¹³å‡ç½®ä¿¡åº¦": round(avg_confidence, 3),
            "æœ€éœ€å…³æ³¨è®¾å¤‡": focus_devices[0]["device_name"] if focus_devices else "æ— ",
            "ä¸»è¦é—®é¢˜ç±»å‹": (
                max(match_type_counts.items(), key=lambda x: x[1])[0]
                if match_type_counts
                else "æ— "
            ),
        }

    def _generate_actionable_recommendations(
        self, high_priority: List, medium_priority: List
    ) -> List[Dict]:
        """ç”Ÿæˆå¯æ‰§è¡Œçš„è¡ŒåŠ¨å»ºè®®"""
        recommendations = []

        # é«˜ä¼˜å…ˆçº§è®¾å¤‡å»ºè®®
        for device in high_priority[:3]:  # åªå¤„ç†å‰3ä¸ªæœ€é‡è¦çš„
            rec = {
                "è®¾å¤‡å": device["device_name"],
                "ä¼˜å…ˆçº§": "ğŸ”´ é«˜",
                "ç½®ä¿¡åº¦": device["confidence_score"],
                "é—®é¢˜ç±»å‹": device["match_type"],
                "å»ºè®®è¡ŒåŠ¨": self._get_specific_recommendation(device),
                "é¢„è®¡å·¥ä½œé‡": "2-4å°æ—¶",
            }
            recommendations.append(rec)

        # ä¸­ä¼˜å…ˆçº§è®¾å¤‡å»ºè®®
        for device in medium_priority[:2]:  # åªå¤„ç†å‰2ä¸ª
            rec = {
                "è®¾å¤‡å": device["device_name"],
                "ä¼˜å…ˆçº§": "ğŸŸ¡ ä¸­",
                "ç½®ä¿¡åº¦": device["confidence_score"],
                "é—®é¢˜ç±»å‹": device["match_type"],
                "å»ºè®®è¡ŒåŠ¨": self._get_specific_recommendation(device),
                "é¢„è®¡å·¥ä½œé‡": "1-2å°æ—¶",
            }
            recommendations.append(rec)

        return recommendations

    def _get_specific_recommendation(self, device: Dict) -> str:
        """æ ¹æ®è®¾å¤‡æƒ…å†µç”Ÿæˆå…·ä½“å»ºè®®"""
        match_type = device["match_type"]
        confidence = device["confidence_score"]

        if match_type == "å®Œå…¨ä¸åŒ¹é…":
            return "å®Œæ•´é‡æ–°è®¾è®¡IOåˆ†é…æ–¹æ¡ˆ"
        elif match_type == "éƒ¨åˆ†åŒ¹é…":
            if confidence < 0.5:
                return "é‡ç‚¹å®¡æŸ¥å·®å¼‚å¹³å°ï¼ŒéªŒè¯åŠŸèƒ½å®Œæ•´æ€§"
            else:
                return "å¾®è°ƒå¹³å°åˆ†é…ï¼Œå¯¹é½AIå»ºè®®"
        elif match_type == "AIç‹¬æœ‰å»ºè®®":
            return "è¯„ä¼°AIå»ºè®®çš„å¿…è¦æ€§ï¼Œè€ƒè™‘é‡‡çº³"
        elif match_type == "ç°æœ‰ç‹¬æœ‰åˆ†é…":
            return "éªŒè¯ç°æœ‰åˆ†é…çš„åˆç†æ€§ï¼Œè€ƒè™‘ç§»é™¤å†—ä½™"
        else:
            return "æ·±å…¥åˆ†æå·®å¼‚åŸå› ï¼Œåˆ¶å®šé’ˆå¯¹æ€§æ–¹æ¡ˆ"

    def _enhance_report_with_ai_analysis(
        self, report: Dict[str, Any], analysis_results: List[EnhancedAnalysisResult]
    ) -> Dict[str, Any]:
        """å¢å¼ºæŠ¥å‘Šä»¥åŒ…å«çº¯AIåˆ†æä¿¡æ¯"""

        # ç»Ÿè®¡AIåˆ†æç»“æœ
        ai_analyzed_devices = [r for r in analysis_results if r.ai_analysis_result]
        multi_io_devices = [r for r in analysis_results if r.is_multi_io_device]
        bitmask_devices = [r for r in analysis_results if r.bitmask_ios]
        multi_platform_devices = [r for r in analysis_results if r.multi_platform_ios]

        # ç½®ä¿¡åº¦ç»Ÿè®¡
        if ai_analyzed_devices:
            avg_ai_confidence = sum(
                r.ai_analysis_result.analysis_confidence for r in ai_analyzed_devices
            ) / len(ai_analyzed_devices)
            high_confidence_devices = [
                r
                for r in ai_analyzed_devices
                if r.ai_analysis_result.analysis_confidence >= 0.8
            ]
        else:
            avg_ai_confidence = 0.0
            high_confidence_devices = []

        # æ·»åŠ çº¯AIåˆ†æéƒ¨åˆ†åˆ°æŠ¥å‘Š
        report["çº¯AIåˆ†æç»“æœ"] = {
            "AIåˆ†æè®¾å¤‡æ•°": len(ai_analyzed_devices),
            "å¤šIOè®¾å¤‡æ•°": len(multi_io_devices),
            "Bitmaskè®¾å¤‡æ•°": len(bitmask_devices),
            "å¤šå¹³å°åˆ†é…è®¾å¤‡æ•°": len(multi_platform_devices),
            "å¹³å‡AIç½®ä¿¡åº¦": round(avg_ai_confidence, 3),
            "é«˜ç½®ä¿¡åº¦è®¾å¤‡æ•°": len(high_confidence_devices),
            "å¤šIOè®¾å¤‡åˆ—è¡¨": [r.device_name for r in multi_io_devices],
            "Bitmaskè®¾å¤‡åˆ—è¡¨": [r.device_name for r in bitmask_devices],
            "å¤šå¹³å°åˆ†é…è®¾å¤‡åˆ—è¡¨": [r.device_name for r in multi_platform_devices],
        }

        # å¢å¼ºè¯¦ç»†ç»“æœä»¥åŒ…å«AIåˆ†æå­—æ®µ
        for detail in report["è¯¦ç»†ç»“æœ"]:
            device_name = detail["è®¾å¤‡åç§°"]
            matching_result = next(
                (r for r in analysis_results if r.device_name == device_name), None
            )

            if matching_result:
                detail["æ˜¯å¦å¤šIOè®¾å¤‡"] = matching_result.is_multi_io_device
                detail["Bitmask IOæ•°é‡"] = len(matching_result.bitmask_ios or [])
                detail["å¤šå¹³å°IOæ•°é‡"] = len(matching_result.multi_platform_ios or [])
                detail["AIåˆ†æç½®ä¿¡åº¦"] = (
                    round(matching_result.ai_analysis_result.analysis_confidence, 3)
                    if matching_result.ai_analysis_result
                    else 0.0
                )

        return report

    def _perform_documentation_validation(
        self,
        doc_ios_map: Dict[str, List[str]],
        device_mappings: Dict[str, Any],
        analysis_results: List[EnhancedAnalysisResult],
    ) -> Dict[str, Any]:
        """æ‰§è¡Œå®˜æ–¹æ–‡æ¡£éªŒè¯å¯¹æ¯”"""

        # ç»Ÿè®¡åˆ†æ
        doc_device_count = len(doc_ios_map)
        mapping_device_count = len(device_mappings)

        # IOå£æ•°é‡ç»Ÿè®¡ - ä¿®å¤è®¡ç®—é€»è¾‘
        total_doc_ios = sum(len(ios) for ios in doc_ios_map.values())
        total_mapping_ios = sum(len(result.mapped_ios) for result in analysis_results)

        # è®¾å¤‡è¦†ç›–ç‡åˆ†æ
        doc_devices = set(doc_ios_map.keys())
        mapping_devices = set(device_mappings.keys())

        covered_devices = doc_devices & mapping_devices
        missing_in_mapping = doc_devices - mapping_devices
        extra_in_mapping = mapping_devices - doc_devices

        coverage_rate = len(covered_devices) / len(doc_devices) if doc_devices else 0

        return {
            "è®¾å¤‡æ•°é‡å¯¹æ¯”": {
                "å®˜æ–¹æ–‡æ¡£è®¾å¤‡æ•°": doc_device_count,
                "æ˜ å°„é…ç½®è®¾å¤‡æ•°": mapping_device_count,
                "è¦†ç›–è®¾å¤‡æ•°": len(covered_devices),
                "è®¾å¤‡è¦†ç›–ç‡": f"{coverage_rate:.1%}",
            },
            "IOå£æ•°é‡å¯¹æ¯”": {
                "å®˜æ–¹æ–‡æ¡£IOå£æ€»æ•°": total_doc_ios,
                "æ˜ å°„é…ç½®IOå£æ€»æ•°": total_mapping_ios,
                "IOå£åŒ¹é…ç‡": (
                    f"{(total_mapping_ios/total_doc_ios):.1%}"
                    if total_doc_ios > 0
                    else "0%"
                ),
            },
            "è®¾å¤‡è¦†ç›–åˆ†æ": {
                "å·²è¦†ç›–è®¾å¤‡": list(covered_devices),
                "æ–‡æ¡£ä¸­ç¼ºå¤±çš„è®¾å¤‡": list(missing_in_mapping),
                "æ˜ å°„ä¸­é¢å¤–çš„è®¾å¤‡": list(extra_in_mapping),
            },
        }

    def _generate_comprehensive_report(
        self,
        analysis_results: List[EnhancedAnalysisResult],
        validation_results: Dict[str, Any],
        doc_ios_map: Dict[str, List[str]],
        device_mappings: Dict[str, Any],
    ) -> Dict[str, Any]:
        """ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š"""

        # åŸºç¡€ç»Ÿè®¡
        total_devices = len(analysis_results)
        problem_devices = [r for r in analysis_results if r.match_score < 0.9]
        excellent_devices = [r for r in analysis_results if r.match_score >= 0.9]

        # å¹³å°åˆ†é…é—®é¢˜ç»Ÿè®¡
        platform_issues = [r for r in analysis_results if r.platform_allocation_issues]

        # ç”Ÿæˆæ¦‚è§ˆ
        analysis_overview = {
            "ç”Ÿæˆæ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "å·¥å…·ç‰ˆæœ¬": "RUN_THIS_TOOL.py v4.2 (å®æ—¶NLPç‰ˆ)",
            "åˆ†ææ¨¡å¼": "åŒé‡éªŒè¯æœºåˆ¶ (çº¯AIåˆ†æ + å®˜æ–¹æ–‡æ¡£éªŒè¯)",
            "æ”¯æŒå¹³å°æ•°": len(self.supported_platforms),
            "æ€»è®¾å¤‡æ•°": total_devices,
            "ä¼˜ç§€è®¾å¤‡æ•°": len(excellent_devices),
            "é—®é¢˜è®¾å¤‡æ•°": len(problem_devices),
            "å¹³å°åˆ†é…é—®é¢˜è®¾å¤‡": len(platform_issues),
            "æ•´ä½“åŒ¹é…ç‡": (
                f"{(len(excellent_devices)/total_devices*100):.1f}%"
                if total_devices > 0
                else "0%"
            ),
        }

        # é—®é¢˜è®¾å¤‡åˆ†æ
        problem_analysis = self._analyze_problem_devices(problem_devices)

        # æ”¹è¿›å»ºè®®
        improvement_suggestions = self._generate_improvement_suggestions(
            problem_devices
        )

        # åŠŸèƒ½çŠ¶æ€
        feature_status = {
            "çº¯AIåˆ†æ": "âœ… å·²å¯ç”¨",
            "å®˜æ–¹æ–‡æ¡£è§£æ": "âœ… å·²å¯ç”¨",
            "åŒé‡éªŒè¯æœºåˆ¶": "âœ… å·²å¯ç”¨",
            "IOå£é€»è¾‘åˆ†æ": "âœ… å·²å¯ç”¨",
            "å¹³å°åˆ†é…éªŒè¯": "âœ… å·²å¯ç”¨",
            "Bitmaskæ£€æµ‹": "âœ… å·²å¯ç”¨",
            "å¤šå¹³å°åˆ†é…": "âœ… å·²å¯ç”¨",
            "æ€§èƒ½ç›‘æ§": "âœ… å·²å¯ç”¨",
            "æ”¯æŒçš„å¹³å°": list(self.supported_platforms),
        }

        return {
            "åˆ†ææ¦‚è§ˆ": analysis_overview,
            "å®˜æ–¹æ–‡æ¡£éªŒè¯": validation_results,
            "é—®é¢˜è®¾å¤‡åˆ†æ": problem_analysis,
            "æ”¹è¿›å»ºè®®": improvement_suggestions,
            "åŠŸèƒ½çŠ¶æ€": feature_status,
            "è¯¦ç»†ç»“æœ": [
                {
                    "è®¾å¤‡åç§°": r.device_name,
                    "åŒ¹é…åˆ†æ•°": round(r.match_score, 3),
                    "å¹³å°åˆ†é…åˆ†æ•°": round(r.platform_allocation_score, 3),
                    "åˆ†æç­–ç•¥": r.analysis_type,
                    "æ–‡æ¡£IOå£": list(r.doc_ios),
                    "æ˜ å°„IOå£": list(r.mapped_ios),
                    "å¹³å°åˆ†é…é—®é¢˜": len(r.platform_allocation_issues or []),
                }
                for r in analysis_results
                # åŒ…å«æ‰€æœ‰è®¾å¤‡çš„è¯¦ç»†ç»“æœï¼Œè€Œä¸ä»…ä»…æ˜¯é—®é¢˜è®¾å¤‡
            ],
        }

    def _analyze_problem_devices(
        self, problem_devices: List[EnhancedAnalysisResult]
    ) -> Dict[str, Any]:
        """åˆ†æé—®é¢˜è®¾å¤‡"""
        # æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†ç»„
        critical_devices = [r for r in problem_devices if r.match_score == 0]
        major_issues = [r for r in problem_devices if 0 < r.match_score < 0.5]
        minor_issues = [r for r in problem_devices if 0.5 <= r.match_score < 0.9]

        return {
            "å…³é”®é—®é¢˜è®¾å¤‡": {
                "æ•°é‡": len(critical_devices),
                "è¯´æ˜": "å®Œå…¨ä¸åŒ¹é…ï¼Œéœ€è¦ç«‹å³ä¿®å¤",
                "è®¾å¤‡åˆ—è¡¨": [r.device_name for r in critical_devices],
            },
            "ä¸¥é‡é—®é¢˜è®¾å¤‡": {
                "æ•°é‡": len(major_issues),
                "è¯´æ˜": "åŒ¹é…åº¦å¾ˆä½ï¼Œéœ€è¦é‡ç‚¹å…³æ³¨",
                "è®¾å¤‡åˆ—è¡¨": [r.device_name for r in major_issues],
            },
            "è½»å¾®é—®é¢˜è®¾å¤‡": {
                "æ•°é‡": len(minor_issues),
                "è¯´æ˜": "éƒ¨åˆ†åŒ¹é…ï¼Œéœ€è¦å®Œå–„",
                "è®¾å¤‡åˆ—è¡¨": [r.device_name for r in minor_issues],
            },
        }

    def _generate_improvement_suggestions(
        self, problem_devices: List[EnhancedAnalysisResult]
    ) -> List[Dict[str, Any]]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        suggestions = []

        # æŒ‰åŒ¹é…åˆ†æ•°æ’åºï¼Œä¼˜å…ˆæ˜¾ç¤ºæœ€ä¸¥é‡çš„é—®é¢˜
        problem_devices.sort(key=lambda x: x.match_score)

        for result in problem_devices[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ªæœ€éœ€è¦å…³æ³¨çš„
            suggestion = {
                "è®¾å¤‡åç§°": result.device_name,
                "å½“å‰åˆ†æ•°": round(result.match_score, 3),
                "å¹³å°åˆ†é…åˆ†æ•°": round(result.platform_allocation_score, 3),
                "ä¼˜å…ˆçº§": self._get_priority_level(result.match_score),
                "é—®é¢˜ç±»å‹": [],
                "å…·ä½“å»ºè®®": [],
            }

            # åˆ†æé—®é¢˜ç±»å‹å’Œå»ºè®®
            if result.unmatched_doc:
                suggestion["é—®é¢˜ç±»å‹"].append("ç¼ºå¤±æ˜ å°„IOå£")
                suggestion["å…·ä½“å»ºè®®"].append(
                    f"éœ€è¦æ·»åŠ ä»¥ä¸‹IOå£çš„æ˜ å°„: {', '.join(result.unmatched_doc)}"
                )

            if result.unmatched_mapping:
                suggestion["é—®é¢˜ç±»å‹"].append("å¤šä½™æ˜ å°„IOå£")
                suggestion["å…·ä½“å»ºè®®"].append(
                    f"ä»¥ä¸‹IOå£åœ¨æ–‡æ¡£ä¸­æ‰¾ä¸åˆ°å¯¹åº”: {', '.join(result.unmatched_mapping)}"
                )

            if result.platform_allocation_issues:
                suggestion["é—®é¢˜ç±»å‹"].append("å¹³å°åˆ†é…é—®é¢˜")
                suggestion["å…·ä½“å»ºè®®"].append(
                    f"æ£€æµ‹åˆ° {len(result.platform_allocation_issues)} ä¸ªå¹³å°åˆ†é…é—®é¢˜"
                )

            suggestions.append(suggestion)

        return suggestions

    def _get_priority_level(self, score: float) -> str:
        """æ ¹æ®åŒ¹é…åˆ†æ•°ç¡®å®šä¼˜å…ˆçº§"""
        if score == 0:
            return "ğŸ”´ ç´§æ€¥"
        elif score < 0.5:
            return "ğŸŸ  é«˜"
        elif score < 0.9:
            return "ğŸŸ¡ ä¸­"
        else:
            return "ğŸŸ¢ ä½"

    def save_analysis_report(self, report: Dict[str, Any], output_path: str):
        """ä¿å­˜åˆ†ææŠ¥å‘Šåˆ°æ–‡ä»¶"""
        import json

        try:
            with open(output_path, "w", encoding="utf-8") as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            print(f"âœ… JSONåˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")
        except Exception as e:
            print(f"âŒ ä¿å­˜JSONæŠ¥å‘Šå¤±è´¥: {e}")

    def generate_smart_markdown_report(self, report: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ™ºèƒ½èšç„¦çš„MarkdownæŠ¥å‘Š - ç§»é™¤æ— ç”¨ä¿¡æ¯"""
        md_content = []

        # æ ‡é¢˜å’ŒåŸºæœ¬ä¿¡æ¯
        md_content.append("# ğŸ¯ æ™ºèƒ½IOåˆ†é…å¯¹æ¯”åˆ†ææŠ¥å‘Š")
        md_content.append("")
        md_content.append(f"**ç”Ÿæˆæ—¶é—´**: {report['åˆ†ææ¦‚è§ˆ']['ç”Ÿæˆæ—¶é—´']}")
        md_content.append(f"**å·¥å…·ç‰ˆæœ¬**: {report['åˆ†ææ¦‚è§ˆ']['å·¥å…·ç‰ˆæœ¬']}")
        md_content.append(f"**åˆ†ææ¨¡å¼**: {report['åˆ†ææ¦‚è§ˆ']['åˆ†ææ¨¡å¼']}")
        md_content.append(
            "**æ ¸å¿ƒç‰¹è‰²**: ğŸ¯ ä¸“æ³¨å·®å¼‚è®¾å¤‡ | ğŸš« æ— ç”¨æŠ¥å‘Šå·²ç§»é™¤ | ğŸ’° æ™ºèƒ½å¤„ç†ä¼˜åŒ–"
        )
        md_content.append("")
        md_content.append("---")
        md_content.append("")

        # åˆ†ææ¦‚è§ˆ
        overview = report["åˆ†ææ¦‚è§ˆ"]
        md_content.append("## ğŸ“Š æ ¸å¿ƒç»Ÿè®¡")
        md_content.append("")
        md_content.append("| æŒ‡æ ‡ | æ•°å€¼ | è¯´æ˜ |")
        md_content.append("|------|------|------|")
        md_content.append(f"| **æ€»è®¾å¤‡æ•°** | {overview['æ€»è®¾å¤‡æ•°']}ä¸ª | åˆ†æè¦†ç›–è®¾å¤‡ |")
        md_content.append(
            f"| **éœ€è¦å…³æ³¨è®¾å¤‡** | {overview['éœ€è¦å…³æ³¨è®¾å¤‡æ•°']}ä¸ª | å­˜åœ¨å·®å¼‚çš„è®¾å¤‡ |"
        )
        md_content.append(
            f"| **å·²è¿‡æ»¤è®¾å¤‡** | {overview['å·²è¿‡æ»¤è®¾å¤‡æ•°']}ä¸ª | 100%åŒ¹é…çš„è®¾å¤‡ |"
        )
        md_content.append(f"| **å¤„ç†æ•ˆç‡** | {overview['å¤„ç†æ•ˆç‡']} | æ™ºèƒ½åˆ†ææ•ˆæœ |")
        md_content.append("")

        # æ™ºèƒ½è¿‡æ»¤ç»“æœ
        filtering = report["æ™ºèƒ½è¿‡æ»¤ç»“æœ"]
        md_content.append("## ğŸ¤– æ™ºèƒ½è¿‡æ»¤æˆæ•ˆ")
        md_content.append("")
        md_content.append(f"- **è¿‡æ»¤ç­–ç•¥**: {filtering['è¿‡æ»¤ç­–ç•¥']}")
        md_content.append(f"- **é«˜åŒ¹é…åº¦è®¾å¤‡**: {filtering['é«˜åŒ¹é…åº¦è®¾å¤‡']}ä¸ªè®¾å¤‡")
        md_content.append(f"- **éœ€è¦å…³æ³¨è®¾å¤‡**: {filtering['éœ€è¦å…³æ³¨è®¾å¤‡']}ä¸ªè®¾å¤‡")
        md_content.append("")

        if filtering.get("è¿‡æ»¤è®¾å¤‡åˆ—è¡¨"):
            md_content.append("**è¢«è¿‡æ»¤çš„é«˜åŒ¹é…åº¦è®¾å¤‡** (å‰10ä¸ª):")
            for device in filtering["è¿‡æ»¤è®¾å¤‡åˆ—è¡¨"]:
                md_content.append(f"- `{device}` âœ…")
            md_content.append("")

        # å·®å¼‚è®¾å¤‡åˆ†æ - æ˜¾ç¤ºæ‰€æœ‰å·®å¼‚è®¾å¤‡çš„è¯¦ç»†ä¿¡æ¯
        diff_analysis = report["å·®å¼‚è®¾å¤‡åˆ†æ"]
        md_content.append("## ğŸ” éœ€è¦å…³æ³¨çš„å·®å¼‚è®¾å¤‡")
        md_content.append("")

        # è®¡ç®—æ€»è®¾å¤‡æ•°ä»¥ä¾¿æ­£ç¡®æ˜¾ç¤ºæ‰€æœ‰è®¾å¤‡
        total_devices_in_analysis = sum(info["æ•°é‡"] for info in diff_analysis.values())
        md_content.append(
            f"**å…±åˆ†æ {total_devices_in_analysis} ä¸ªè®¾å¤‡ï¼Œè¯¦ç»†ä¿¡æ¯å¦‚ä¸‹ï¼š**"
        )
        md_content.append("")

        for priority_level, info in diff_analysis.items():
            if info["æ•°é‡"] > 0:
                icon = (
                    "ğŸ”´"
                    if "é«˜ä¼˜å…ˆçº§" in priority_level
                    else "ğŸŸ¡" if "ä¸­ä¼˜å…ˆçº§" in priority_level else "ğŸŸ¢"
                )
                md_content.append(f"### {icon} {priority_level} ({info['æ•°é‡']}ä¸ª)")
                md_content.append(f"*{info['è¯´æ˜']}*")
                md_content.append("")

                # åˆ›å»ºè¯¦ç»†å¯¹æ¯”è¡¨æ ¼
                if info["è®¾å¤‡åˆ—è¡¨"]:
                    md_content.append(
                        "| è®¾å¤‡å | ç½®ä¿¡åº¦ | ç±»å‹ | ç°æœ‰å¹³å° | AIæ¨èå¹³å° | ç°æœ‰IOå£ | AIæ¨èIOå£ | ä¸åŒ¹é…åŸå›  |"
                    )
                    md_content.append(
                        "|--------|--------|------|----------|------------|----------|------------|------------|"
                    )

                    for device in info["è®¾å¤‡åˆ—è¡¨"]:
                        device_name = device.get("è®¾å¤‡å", "N/A")
                        confidence = device.get("ç½®ä¿¡åº¦", 0)
                        match_type = device.get("ç±»å‹", "N/A")
                        existing_platforms = ", ".join(device.get("ç°æœ‰å¹³å°é…ç½®", []))
                        ai_platforms = ", ".join(device.get("AIæ¨èå¹³å°é…ç½®", []))
                        existing_ios = ", ".join(
                            device.get("ç°æœ‰IOå£", [])[:3]
                        )  # åªæ˜¾ç¤ºå‰3ä¸ªIOå£
                        ai_ios = ", ".join(
                            device.get("AIæ¨èIOå£", [])[:3]
                        )  # åªæ˜¾ç¤ºå‰3ä¸ªIOå£
                        reason = device.get("ä¸åŒ¹é…åŸå› ", "N/A")[:100] + (
                            "..." if len(device.get("ä¸åŒ¹é…åŸå› ", "")) > 100 else ""
                        )  # é™åˆ¶é•¿åº¦

                        md_content.append(
                            f"| **{device_name}** | {confidence:.3f} | {match_type} | {existing_platforms or 'N/A'} | {ai_platforms or 'N/A'} | {existing_ios or 'N/A'} | {ai_ios or 'N/A'} | {reason} |"
                        )

                md_content.append("")

        # æ ¸å¿ƒå‘ç°
        insights = report["æ ¸å¿ƒå‘ç°"]
        md_content.append("## ğŸ’¡ æ ¸å¿ƒå‘ç°")
        md_content.append("")

        if insights.get("çŠ¶æ€"):
            md_content.append(f"ğŸ‰ **{insights['çŠ¶æ€']}**")
        else:
            md_content.append(
                f"- **ä¸»è¦é—®é¢˜ç±»å‹**: {insights.get('ä¸»è¦é—®é¢˜ç±»å‹', 'N/A')}"
            )
            md_content.append(f"- **å¹³å‡ç½®ä¿¡åº¦**: {insights.get('å¹³å‡ç½®ä¿¡åº¦', 'N/A')}")
            md_content.append(
                f"- **æœ€éœ€å…³æ³¨è®¾å¤‡**: `{insights.get('æœ€éœ€å…³æ³¨è®¾å¤‡', 'N/A')}`"
            )
            md_content.append("")

            if insights.get("å·®å¼‚ç±»å‹åˆ†å¸ƒ"):
                md_content.append("**å·®å¼‚ç±»å‹åˆ†å¸ƒ**:")
                for diff_type, count in insights["å·®å¼‚ç±»å‹åˆ†å¸ƒ"].items():
                    md_content.append(f"- {diff_type}: {count}ä¸ª")

        md_content.append("")

        # è¡ŒåŠ¨å»ºè®®
        recommendations = report["è¡ŒåŠ¨å»ºè®®"]
        if recommendations:
            md_content.append("## ğŸ¯ ç«‹å³è¡ŒåŠ¨å»ºè®®")
            md_content.append("")

            for i, rec in enumerate(recommendations, 1):
                md_content.append(f"### {i}. {rec['è®¾å¤‡å']} - {rec['ä¼˜å…ˆçº§']}")
                md_content.append(f"**é—®é¢˜ç±»å‹**: {rec['é—®é¢˜ç±»å‹']}")
                md_content.append(f"**ç½®ä¿¡åº¦**: {rec['ç½®ä¿¡åº¦']:.3f}")
                md_content.append(f"**å»ºè®®è¡ŒåŠ¨**: {rec['å»ºè®®è¡ŒåŠ¨']}")
                md_content.append(f"**é¢„è®¡å·¥ä½œé‡**: {rec['é¢„è®¡å·¥ä½œé‡']}")
                md_content.append("")

        # åŠŸèƒ½çŠ¶æ€è¯´æ˜
        md_content.append("## âœ… å‡çº§åŠŸèƒ½è¯´æ˜")
        md_content.append("")
        feature_status = report["åŠŸèƒ½çŠ¶æ€"]
        for feature, status in feature_status.items():
            md_content.append(f"- **{feature}**: {status}")
        md_content.append("")

        md_content.append("---")
        md_content.append("")
        md_content.append("## ğŸ“‹ é‡è¦è¯´æ˜")
        md_content.append("")
        md_content.append("### ğŸ¯ å‡çº§äº®ç‚¹")
        md_content.append("1. **ä¸“æ³¨å·®å¼‚**: åªå…³æ³¨éœ€è¦äººå·¥å¹²é¢„çš„ä¸ä¸€è‡´è®¾å¤‡")
        md_content.append("2. **æ™ºèƒ½è¿‡æ»¤**: è‡ªåŠ¨è¿‡æ»¤100%åŒ¹é…çš„é«˜ç½®ä¿¡åº¦è®¾å¤‡")
        md_content.append("3. **TokenèŠ‚çœ**: é¿å…å¯¹å®Œç¾åŒ¹é…è®¾å¤‡æµªè´¹AIèµ„æº")
        md_content.append(
            "4. **æ— ç”¨ä¿¡æ¯ç§»é™¤**: ä¸å†æ˜¾ç¤ºå¤šIOè®¾å¤‡å’ŒBitmaskè®¾å¤‡ç­‰æ— å…³ä¿¡æ¯"
        )
        md_content.append("")
        md_content.append("### ğŸš« å·²ç§»é™¤çš„æ— ç”¨æŠ¥å‘Š")
        md_content.append("- âŒ å¤šIOè®¾å¤‡åˆ—è¡¨ (ä¸æ ¸å¿ƒéœ€æ±‚æ— å…³)")
        md_content.append("- âŒ Bitmaskè®¾å¤‡æŠ¥å‘Š (ä¸æ ¸å¿ƒéœ€æ±‚æ— å…³)")
        md_content.append("- âŒ 100%åŒ¹é…è®¾å¤‡çš„å†—ä½™ä¿¡æ¯")
        md_content.append("")
        md_content.append("---")
        md_content.append("")
        md_content.append("*ğŸ“‹ æ­¤æŠ¥å‘Šç”±RUN_THIS_TOOL.py v4.2 (å®æ—¶NLPç‰ˆ) è‡ªåŠ¨ç”Ÿæˆ*")
        md_content.append(f"*ğŸ”„ åŸºäºAgent1(å†…å­˜æ¨¡å¼) + å®æ—¶NLPåˆ†æçš„æ™ºèƒ½ç»“æœ*")
        md_content.append(f"*ğŸ“– é›¶æ–‡ä»¶ä¾èµ–ï¼Œç›´æ¥åŸºäºæœ€æ–°å®˜æ–¹æ–‡æ¡£å®æ—¶åˆ†æ*")

        return "\n".join(md_content)

    def save_smart_markdown_report(self, report: Dict[str, Any], output_path: str):
        """ä¿å­˜æ™ºèƒ½èšç„¦çš„Markdownæ ¼å¼æŠ¥å‘Š"""
        try:
            markdown_content = self.generate_smart_markdown_report(report)
            # ç¡®ä¿æ–‡ä»¶æœ«å°¾æœ‰æ¢è¡Œç¬¦
            if not markdown_content.endswith("\n"):
                markdown_content += "\n"
            with open(output_path, "w", encoding="utf-8") as f:
                f.write(markdown_content)
            print(f"âœ… æ™ºèƒ½èšç„¦MarkdownæŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")
        except Exception as e:
            print(f"âŒ ä¿å­˜MarkdownæŠ¥å‘Šå¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•° - æ‰§è¡Œæ™ºèƒ½IOåˆ†é…å¯¹æ¯”åˆ†æ"""

    # æ–‡æ¡£è·¯å¾„
    doc_path = os.path.join(
        os.path.dirname(__file__), "../../docs/LifeSmart æ™ºæ…§è®¾å¤‡è§„æ ¼å±æ€§è¯´æ˜.md"
    )

    # è¾“å‡ºè·¯å¾„
    json_output_path = os.path.join(
        os.path.dirname(__file__), "smart_analysis_report.json"
    )
    markdown_output_path = os.path.join(
        os.path.dirname(__file__), "SMART_ANALYSIS_SUMMARY.md"
    )

    # åˆ›å»ºæ™ºèƒ½åˆ†æå™¨å¹¶æ‰§è¡Œåˆ†æ
    analyzer = SmartIOAllocationAnalyzer(enable_performance_monitoring=True)

    try:
        # æ‰§è¡Œæ™ºèƒ½å¯¹æ¯”åˆ†æ
        report = analyzer.perform_smart_comparison_analysis(doc_path)

        # ä¿å­˜JSONæŠ¥å‘Š
        analyzer.save_analysis_report(report, json_output_path)

        # ä¿å­˜æ™ºèƒ½èšç„¦MarkdownæŠ¥å‘Š
        analyzer.save_smart_markdown_report(report, markdown_output_path)

        # æ‰“å°å…³é”®ç»Ÿè®¡ä¿¡æ¯
        print("\\n" + "=" * 80)
        print("ğŸ¯ æ™ºèƒ½IOåˆ†é…å¯¹æ¯”åˆ†æç»“æœæ¦‚è§ˆ v4.2 (å®æ—¶NLPç‰ˆ)")
        print("=" * 80)

        overview = report["åˆ†ææ¦‚è§ˆ"]
        print(f"åˆ†ææ¨¡å¼: {overview['åˆ†ææ¨¡å¼']}")
        print(f"æ€»è®¾å¤‡æ•°: {overview['æ€»è®¾å¤‡æ•°']}")
        print(f"éœ€è¦å…³æ³¨è®¾å¤‡æ•°: {overview['éœ€è¦å…³æ³¨è®¾å¤‡æ•°']}")
        print(f"å·²è¿‡æ»¤è®¾å¤‡æ•°: {overview['å·²è¿‡æ»¤è®¾å¤‡æ•°']}")
        print(f"å¤„ç†æ•ˆç‡: {overview['å¤„ç†æ•ˆç‡']}")

        # æ˜¾ç¤ºæ™ºèƒ½è¿‡æ»¤æˆæ•ˆ
        filtering = report["æ™ºèƒ½è¿‡æ»¤ç»“æœ"]
        print(f"\\nğŸ¤– æ™ºèƒ½è¿‡æ»¤æˆæ•ˆ:")
        print(f"  é«˜åŒ¹é…åº¦è®¾å¤‡: {filtering['é«˜åŒ¹é…åº¦è®¾å¤‡']}ä¸ªè®¾å¤‡")
        print(f"  éœ€è¦å…³æ³¨è®¾å¤‡: {filtering['éœ€è¦å…³æ³¨è®¾å¤‡']}ä¸ªè®¾å¤‡")

        # æ˜¾ç¤ºå·®å¼‚è®¾å¤‡åˆ†æ
        diff_analysis = report["å·®å¼‚è®¾å¤‡åˆ†æ"]
        print(f"\\nğŸ” å·®å¼‚è®¾å¤‡åˆ†ç±»:")
        for priority_level, info in diff_analysis.items():
            if info["æ•°é‡"] > 0:
                print(f"  {priority_level}: {info['æ•°é‡']}ä¸ª")

        # æ˜¾ç¤ºæ ¸å¿ƒå‘ç°
        insights = report["æ ¸å¿ƒå‘ç°"]
        print(f"\\nğŸ’¡ æ ¸å¿ƒå‘ç°:")
        if insights.get("çŠ¶æ€"):
            print(f"  çŠ¶æ€: {insights['çŠ¶æ€']}")
        else:
            print(f"  ä¸»è¦é—®é¢˜ç±»å‹: {insights.get('ä¸»è¦é—®é¢˜ç±»å‹', 'N/A')}")
            print(f"  å¹³å‡ç½®ä¿¡åº¦: {insights.get('å¹³å‡ç½®ä¿¡åº¦', 'N/A')}")
            print(f"  æœ€éœ€å…³æ³¨è®¾å¤‡: {insights.get('æœ€éœ€å…³æ³¨è®¾å¤‡', 'N/A')}")

        # æ˜¾ç¤ºè¡ŒåŠ¨å»ºè®®
        recommendations = report["è¡ŒåŠ¨å»ºè®®"]
        if recommendations:
            print(f"\\nğŸ¯ ç«‹å³è¡ŒåŠ¨å»ºè®® (å‰{min(3, len(recommendations))}ä¸ª):")
            for i, rec in enumerate(recommendations[:3], 1):
                priority = rec["ä¼˜å…ˆçº§"]
                name = rec["è®¾å¤‡å"]
                confidence = rec["ç½®ä¿¡åº¦"]
                print(f"  {i}. {priority} {name}: ç½®ä¿¡åº¦ {confidence:.3f}")

        print("\\nâœ… æ™ºèƒ½åˆ†ææŠ¥å‘Šå·²ä¿å­˜:")
        print(f"   ğŸ“Š JSONè¯¦ç»†æŠ¥å‘Š: {json_output_path}")
        print(f"   ğŸ“‹ æ™ºèƒ½èšç„¦æŠ¥å‘Š: {markdown_output_path}")
        print(f"\\nğŸ¯ v4.2å‡çº§åŠŸèƒ½è¯´æ˜:")
        print(
            f"   ğŸ¤– å®æ—¶NLPåˆ†æ: Agent1(å†…å­˜æ¨¡å¼) + å®æ—¶æ–‡æ¡£è§£æ + NLPåˆ†ç±»å™¨ + æ™ºèƒ½å¯¹æ¯”"
        )
        print(f"   ğŸ“– é›¶æ–‡ä»¶ä¾èµ–: ç§»é™¤Agent3æ–‡ä»¶ä¾èµ–ï¼Œç›´æ¥åŸºäºå®˜æ–¹æ–‡æ¡£è¿›è¡Œå®æ—¶åˆ†æ")
        print(f"   ğŸ¯ å·®å¼‚èšç„¦: åªå…³æ³¨éœ€è¦äººå·¥å¹²é¢„çš„ä¸ä¸€è‡´è®¾å¤‡")
        print(f"   ğŸ’° TokenèŠ‚çœ: æ™ºèƒ½è¿‡æ»¤100%åŒ¹é…çš„é«˜ç½®ä¿¡åº¦è®¾å¤‡")
        print(f"   ğŸš« æ— ç”¨æŠ¥å‘Šç§»é™¤: ä¸å†æ˜¾ç¤ºå¤šIOè®¾å¤‡å’ŒBitmaskè®¾å¤‡ç­‰æ— å…³ä¿¡æ¯")
        print(
            f"   âš¡ æ¶æ„ä¼˜åŒ–: Agent1(å†…å­˜) + å®æ—¶NLPåˆ†æ = å®Œå…¨é›¶ä¾èµ–çš„æ™ºèƒ½åˆ†ææµæ°´çº¿"
        )
        print(f"   ğŸ”¥ æ ¸å¿ƒå‡çº§: ç¬¬3é˜¶æ®µä»æ–‡ä»¶ä¾èµ–å‡çº§ä¸ºå®æ—¶NLPåˆ†æï¼Œæå‡çµæ´»æ€§å’Œå®æ—¶æ€§")

    except Exception as e:
        print(f"âŒ æ™ºèƒ½åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    main()
