#!/usr/bin/env python3
"""
æ™ºèƒ½IOåˆ†é…å¯¹æ¯”åˆ†æå·¥å…· - å‡çº§ç‰ˆ
ä¸“æ³¨äºAIåˆ†ævsç°æœ‰åˆ†é…çš„å¯¹æ¯”ï¼Œæä¾›ç½®ä¿¡åº¦è¯„ä¼°å’Œå·®å¼‚æŠ¥å‘Š
ç§»é™¤æ— ç”¨çš„å¤šIOè®¾å¤‡å’ŒBitmaskæŠ¥å‘Šï¼Œå®ç°æ™ºèƒ½è¿‡æ»¤é¿å…æµªè´¹AI Token
ç”± @MapleEve åˆ›å»ºå’Œç»´æŠ¤

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. AI vs ç°æœ‰åˆ†é…å¯¹æ¯”ï¼šä¸“æ³¨äº493ä¸ªIOæ¥å£çš„åˆ†é…å·®å¼‚åˆ†æ
2. ç½®ä¿¡åº¦è¯„ä¼°ï¼šå¤šç»´åº¦ç½®ä¿¡åº¦æ¨¡å‹ï¼Œè‡ªåŠ¨è¿‡æ»¤100%åŒ¹é…è®¾å¤‡
3. å·®å¼‚èšç„¦æŠ¥å‘Šï¼šåªå…³æ³¨éœ€è¦äººå·¥å¹²é¢„çš„ä¸ä¸€è‡´è®¾å¤‡
4. æ™ºèƒ½Tokenç®¡ç†ï¼šé«˜ç½®ä¿¡åº¦åŒ¹é…è®¾å¤‡ä¸æ¶ˆè€—AIèµ„æº
"""

import json

# Add the custom component to path for importing const.py
import os
import sys
from datetime import datetime
from typing import Dict, Set, List, Any

sys.path.insert(
    0, os.path.join(os.path.dirname(__file__), "../../custom_components/lifesmart")
)

try:
    # Import the device mappings - é€‚é…å½“å‰æ¶æ„
    from core.config.device_specs import _RAW_DEVICE_DATA

    # é‡å‘½åä»¥ä¿æŒå…¼å®¹æ€§
    DEVICE_MAPPING = _RAW_DEVICE_DATA

    # Import utils modules for enhanced analysis
    from utils.strategies import EnhancedAnalysisEngine, EnhancedAnalysisResult
    from utils.io_logic_analyzer import PlatformAllocationValidator
    from utils.document_parser import DocumentParser
    from utils.core_utils import DeviceNameUtils, RegexCache
    from utils.regex_cache import enable_debug_mode, regex_performance_monitor

except ImportError as e:
    print(f"âš ï¸ Import warning: {e}")
    print("ğŸ¯ è¿è¡Œæ™ºèƒ½æ¨¡å¼ï¼šä¾èµ–Agentåˆ†æç»“æœï¼Œè·³è¿‡æœ¬åœ°æ¨¡å—å¯¼å…¥")

    # åˆ›å»ºå ä½ç±»å’Œå‡½æ•°ä»¥é¿å…é”™è¯¯
    class MockAnalysisResult:
        def __init__(self):
            pass

    EnhancedAnalysisResult = MockAnalysisResult
    DEVICE_MAPPING = {}

    def enable_debug_mode():
        pass

    def regex_performance_monitor(func):
        return func


class SmartIOAllocationAnalyzer:
    """æ™ºèƒ½IOåˆ†é…å¯¹æ¯”åˆ†æå™¨ - ä¸“æ³¨å·®å¼‚è®¾å¤‡ï¼Œæ™ºèƒ½è¿‡æ»¤100%åŒ¹é…"""

    def __init__(self, enable_performance_monitoring: bool = False):
        """
        åˆå§‹åŒ–åˆ†æå™¨

        Args:
            enable_performance_monitoring: æ˜¯å¦å¯ç”¨æ€§èƒ½ç›‘æ§
        """
        # è¯»å–SUPPORTED_PLATFORMSé…ç½®
        self.supported_platforms = self._load_supported_platforms()

        try:
            self.document_parser = DocumentParser()
            # åˆ›å»ºå¢å¼ºç‰ˆåˆ†æå¼•æ“
            self.analysis_engine = EnhancedAnalysisEngine(self.supported_platforms)
        except:
            # æ™ºèƒ½æ¨¡å¼ï¼šä½¿ç”¨æ¨¡æ‹Ÿå¯¹è±¡
            print("ğŸ“ ä½¿ç”¨æ™ºèƒ½æ¨¡å¼ï¼šåŸºäºAgentåˆ†æç»“æœ")
            self.document_parser = None
            self.analysis_engine = None

        # æ™ºèƒ½è¿‡æ»¤é…ç½®
        self.confidence_threshold = 0.95  # é«˜ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œè¶…è¿‡æ­¤å€¼è‡ªåŠ¨è¿‡æ»¤
        self.filtered_devices = []  # è¢«è¿‡æ»¤çš„100%åŒ¹é…è®¾å¤‡
        self.focus_devices = []  # éœ€è¦å…³æ³¨çš„å·®å¼‚è®¾å¤‡

        if enable_performance_monitoring:
            enable_debug_mode()

    def _load_supported_platforms(self) -> Set[str]:
        """åŠ è½½å½“å‰æ”¯æŒçš„å¹³å°åˆ—è¡¨ï¼Œæ’é™¤è¢«æ³¨é‡Šçš„å¹³å°"""
        # è¯»å–const.pyæ–‡ä»¶å†…å®¹ - ä¿®æ­£è·¯å¾„è®¡ç®—
        const_file_path = os.path.join(
            os.path.dirname(os.path.dirname(os.path.dirname(__file__))),
            "custom_components/lifesmart/core/const.py",
        )

        active_platforms = set()
        commented_platforms = set()

        try:
            with open(const_file_path, "r", encoding="utf-8") as f:
                content = f.read()

            # æŸ¥æ‰¾SUPPORTED_PLATFORMSå®šä¹‰
            import re

            lines = content.split("\n")
            in_supported_platforms = False

            for line in lines:
                line_stripped = line.strip()

                if "SUPPORTED_PLATFORMS" in line_stripped and "{" in line_stripped:
                    in_supported_platforms = True
                    continue

                if in_supported_platforms:
                    if "}" in line_stripped:
                        break

                    # æ£€æŸ¥å¹³å°å®šä¹‰ - ä¿®å¤æ­£åˆ™è¡¨è¾¾å¼è½¬ä¹‰é—®é¢˜
                    if "Platform." in line_stripped:
                        platform_match = re.search(r"Platform\.(\w+)", line_stripped)
                        if platform_match:
                            platform_name = platform_match.group(1).lower()

                            if line_stripped.startswith("#"):
                                commented_platforms.add(platform_name)
                                print(f"ğŸ”‡ æ£€æµ‹åˆ°è¢«æ³¨é‡Šçš„å¹³å°: {platform_name}")
                            else:
                                active_platforms.add(platform_name)
                                print(f"âœ… æ£€æµ‹åˆ°æ´»è·ƒå¹³å°: {platform_name}")

            print(f"ğŸ“Š å¹³å°çŠ¶æ€ç»Ÿè®¡:")
            print(f"   æ´»è·ƒå¹³å°: {len(active_platforms)} ä¸ª")
            print(f"   è¢«æ³¨é‡Šå¹³å°: {len(commented_platforms)} ä¸ª")

        except Exception as e:
            print(f"âš ï¸ è¯»å–const.pyæ–‡ä»¶å¤±è´¥: {e}")
            # ä½¿ç”¨é»˜è®¤çš„17ä¸ªå¹³å°é…ç½®
            active_platforms = {
                "switch",
                "binary_sensor",
                "sensor",
                "cover",
                "light",
                "climate",
                "remote",
                "fan",
                "lock",
                "camera",
                "alarm_control_panel",
                "device_tracker",
                "media_player",
                "number",
                "select",
                "button",
                "text",
            }
            print(f"ğŸ“‹ ä½¿ç”¨é»˜è®¤å¹³å°é…ç½®: {len(active_platforms)} ä¸ªå¹³å°")

        return active_platforms

    @regex_performance_monitor
    def load_official_documentation(self, doc_path: str) -> Dict[str, List[str]]:
        """
        åŠ è½½å®˜æ–¹æ–‡æ¡£å¹¶æå–IOå£ä¿¡æ¯

        ä¿®å¤ï¼šè½¬æ¢æ ¼å¼ä»Dict[str, List[Dict]] åˆ° Dict[str, List[str]]

        Args:
            doc_path: å®˜æ–¹æ–‡æ¡£è·¯å¾„

        Returns:
            è®¾å¤‡ååˆ°IOå£ååˆ—è¡¨çš„æ˜ å°„ {device_name: [io1, io2, ...]}
        """
        # ä½¿ç”¨æ–‡æ¡£è§£æå™¨æå–åŸå§‹æ•°æ®
        raw_doc_data = self.document_parser.extract_device_ios_from_docs()

        # è½¬æ¢æ ¼å¼ï¼šæå–IOå£åç§°
        device_ios_map = {}
        for device_name, io_definitions in raw_doc_data.items():
            if io_definitions:
                # ä»IOå®šä¹‰ä¸­æå–IOå£åç§°
                io_names = []
                for io_def in io_definitions:
                    if isinstance(io_def, dict) and "name" in io_def:
                        io_names.append(io_def["name"])
                    elif isinstance(io_def, str):
                        io_names.append(io_def)
                device_ios_map[device_name] = io_names
            else:
                device_ios_map[device_name] = []

        print(f"ğŸ“‹ å®˜æ–¹æ–‡æ¡£æ•°æ®è½¬æ¢å®Œæˆ:")
        print(f"   æ‰¾åˆ°è®¾å¤‡: {len(device_ios_map)} ä¸ª")
        total_ios = sum(len(ios) for ios in device_ios_map.values())
        print(f"   æ€»IOå£æ•°: {total_ios} ä¸ª")

        # æ˜¾ç¤ºå‰å‡ ä¸ªè®¾å¤‡çš„IOå£ä¿¡æ¯ç”¨äºè°ƒè¯•
        for i, (device, ios) in enumerate(list(device_ios_map.items())[:3]):
            print(f"   ç¤ºä¾‹è®¾å¤‡ {device}: {ios}")
            if i >= 2:  # åªæ˜¾ç¤ºå‰3ä¸ª
                break

        return device_ios_map

    @regex_performance_monitor
    def prepare_device_mappings_from_real_data(self) -> Dict[str, Any]:
        """
        ä»çœŸå®çš„æ˜ å°„æ•°æ®å‡†å¤‡è®¾å¤‡æ˜ å°„

        Returns:
            æ•´åˆåçš„è®¾å¤‡æ˜ å°„æ•°æ®
        """
        combined_mappings = {}

        # å¤„ç†æ‰€æœ‰è®¾å¤‡æ˜ å°„
        for device_name, device_config in DEVICE_MAPPING.items():
            if self._is_valid_device_for_analysis(device_name):
                # æ£€æŸ¥è®¾å¤‡æ˜¯å¦ä¸ºç‰ˆæœ¬è®¾å¤‡
                if RegexCache.is_version_device(device_name):
                    combined_mappings[device_name] = {
                        "versioned": True,
                        **device_config,
                    }
                # æ£€æŸ¥è®¾å¤‡æ˜¯å¦ä¸ºåŠ¨æ€åˆ†ç±»è®¾å¤‡
                elif self._is_dynamic_classification_device(device_config):
                    combined_mappings[device_name] = {
                        "dynamic": True,
                        **device_config,
                    }
                else:
                    # æ ‡å‡†è®¾å¤‡
                    combined_mappings[device_name] = device_config

        return combined_mappings

    def _is_dynamic_classification_device(self, device_config: Dict[str, Any]) -> bool:
        """æ£€æŸ¥è®¾å¤‡æ˜¯å¦ä¸ºåŠ¨æ€åˆ†ç±»è®¾å¤‡"""
        if not isinstance(device_config, dict):
            return False

        # é€šè¿‡é…ç½®ç»“æ„åˆ¤æ–­
        dynamic_indicators = [
            "control_modes",
            "switch_mode",
            "climate_mode",
            "dynamic",
            "classification",
        ]

        return any(indicator in device_config for indicator in dynamic_indicators)

    def _is_valid_device_for_analysis(self, device_name: str) -> bool:
        """æ£€æŸ¥è®¾å¤‡æ˜¯å¦åº”è¯¥åŒ…å«åœ¨åˆ†æä¸­"""
        return DeviceNameUtils.is_valid_device_name(device_name)

    def _extract_ios_from_device_specs(
        self, device_specs_data: Dict[str, Any]
    ) -> Dict[str, List[str]]:
        """
        ä»device_specsçº¯æ•°æ®ä¸­æå–IOå£ä¿¡æ¯

        è¿™æ˜¯AIåˆ†æçš„åŸºå‡†æ•°æ®æºï¼Œæ¥è‡ªçº¯å‡€çš„è®¾å¤‡è§„æ ¼å®šä¹‰

        Args:
            device_specs_data: device_specs.pyä¸­çš„_RAW_DEVICE_DATA

        Returns:
            è®¾å¤‡ååˆ°IOå£åˆ—è¡¨çš„æ˜ å°„ {device_name: [io1, io2, ...]}
        """
        device_ios_map = {}

        for device_name, device_config in device_specs_data.items():
            if not isinstance(device_config, dict):
                continue

            ios = set()

            # éå†æ‰€æœ‰å¹³å°ç±»å‹ (switch, sensor, light, ç­‰)
            for platform_key, platform_config in device_config.items():
                if platform_key in ["name", "versioned", "dynamic"]:
                    continue

                if isinstance(platform_config, dict):
                    # æå–è¯¥å¹³å°ä¸‹çš„æ‰€æœ‰IOå£åç§°
                    ios.update(platform_config.keys())

            device_ios_map[device_name] = list(ios)

        return device_ios_map

    @regex_performance_monitor
    def perform_smart_comparison_analysis(self, doc_path: str) -> Dict[str, Any]:
        """
        æ‰§è¡Œæ™ºèƒ½IOåˆ†é…å¯¹æ¯”åˆ†æ - ä¸“æ³¨äºå·®å¼‚è®¾å¤‡

        Args:
            doc_path: å®˜æ–¹æ–‡æ¡£è·¯å¾„

        Returns:
            æ™ºèƒ½è¿‡æ»¤åçš„åˆ†æç»“æœå­—å…¸
        """
        print("ğŸš€ å¼€å§‹æ™ºèƒ½IOåˆ†é…å¯¹æ¯”åˆ†æ...")

        # 1. ä½¿ç”¨Agent1çš„åˆ†æç»“æœ - ç°æœ‰åˆ†é…æ•°æ®
        print("ğŸ“š é˜¶æ®µ1: åŠ è½½ç°æœ‰åˆ†é…æ•°æ®...")
        existing_allocation_file = (
            "/Volumes/LocalRAW/lifesmart-HACS-for-hass/tmp/"
            "existing_allocation_complete.json"
        )
        if os.path.exists(existing_allocation_file):
            with open(existing_allocation_file, "r", encoding="utf-8") as f:
                existing_data = json.load(f)
            print(
                f"âœ… åŠ è½½äº†ç°æœ‰åˆ†é…æ•°æ®: {existing_data['metadata']['total_devices']}ä¸ªè®¾å¤‡"
            )
        else:
            # å¦‚æœAgent1ç»“æœä¸å­˜åœ¨ï¼Œä½¿ç”¨åŸæœ‰é€»è¾‘
            device_specs_data = _RAW_DEVICE_DATA
            current_mapping_config = self.prepare_device_mappings_from_real_data()
            existing_data = {"devices": current_mapping_config}
            print(f"âœ… å‡†å¤‡äº†ç°æœ‰æ˜ å°„é…ç½®: {len(current_mapping_config)}ä¸ªè®¾å¤‡")

        # 2. ä½¿ç”¨Agent2çš„åˆ†æç»“æœ - AIåˆ†é…å»ºè®®
        print("ğŸ§  é˜¶æ®µ2: åŠ è½½AIåˆ†é…å»ºè®®...")
        ai_allocation_file = (
            "/Volumes/LocalRAW/lifesmart-HACS-for-hass/tmp/"
            "enhanced_ai_allocation_analysis.json"
        )
        if os.path.exists(ai_allocation_file):
            with open(ai_allocation_file, "r", encoding="utf-8") as f:
                ai_data = json.load(f)
            print(
                f"âœ… åŠ è½½äº†AIåˆ†æå»ºè®®: {len(ai_data.get('device_allocations', {}))}ä¸ªè®¾å¤‡"
            )
        else:
            # å¦‚æœAgent2ç»“æœä¸å­˜åœ¨ï¼Œè¿›è¡ŒåŸºç¡€AIåˆ†æ
            if self.document_parser:
                raw_doc_data = self.document_parser.extract_device_ios_from_docs()
            else:
                raw_doc_data = {}
            ai_data = self._perform_basic_ai_analysis(raw_doc_data, existing_data)
            print(f"âœ… å®ŒæˆåŸºç¡€AIåˆ†æ")

        # 3. ä½¿ç”¨Agent3çš„å¯¹æ¯”åˆ†æç»“æœ
        print("âš–ï¸ é˜¶æ®µ3: åŠ è½½å¯¹æ¯”åˆ†æç»“æœ...")
        comparison_file = (
            "/Volumes/LocalRAW/lifesmart-HACS-for-hass/tmp/"
            "agent3_comparison_analysis_results.json"
        )
        if os.path.exists(comparison_file):
            with open(comparison_file, "r", encoding="utf-8") as f:
                comparison_data = json.load(f)
            print(
                f"âœ… åŠ è½½äº†å¯¹æ¯”åˆ†æç»“æœ: æ€»åŒ¹é…åº¦ {comparison_data.get('overall_match_rate', 'N/A')}"
            )
        else:
            # å¦‚æœAgent3ç»“æœä¸å­˜åœ¨ï¼Œæ‰§è¡ŒåŸºç¡€å¯¹æ¯”
            comparison_data = self._perform_basic_comparison(existing_data, ai_data)
            print("âœ… å®ŒæˆåŸºç¡€å¯¹æ¯”åˆ†æ")

        # 4. æ™ºèƒ½è¿‡æ»¤ï¼šç§»é™¤100%åŒ¹é…è®¾å¤‡ï¼Œèšç„¦å·®å¼‚è®¾å¤‡
        print("ğŸ¯ é˜¶æ®µ4: æ‰§è¡Œæ™ºèƒ½è¿‡æ»¤...")
        filtered_results = self._apply_smart_filtering(comparison_data)
        print(
            f"âœ… æ™ºèƒ½è¿‡æ»¤å®Œæˆ: {len(self.filtered_devices)}ä¸ªè®¾å¤‡è¢«è¿‡æ»¤ï¼Œ{len(self.focus_devices)}ä¸ªè®¾å¤‡éœ€è¦å…³æ³¨"
        )

        # 5. ç”Ÿæˆèšç„¦äºå·®å¼‚çš„æŠ¥å‘Š
        print("ğŸ“Š é˜¶æ®µ5: ç”Ÿæˆå·®å¼‚èšç„¦æŠ¥å‘Š...")
        smart_report = self._generate_smart_report(
            filtered_results, existing_data, ai_data
        )

        print("âœ… æ™ºèƒ½åˆ†æå®Œæˆï¼")
        return smart_report

    def _perform_basic_ai_analysis(
        self, raw_doc_data: Dict, existing_data: Dict
    ) -> Dict[str, Any]:
        """æ‰§è¡ŒåŸºç¡€AIåˆ†æï¼Œå½“Agent2ç»“æœä¸å­˜åœ¨æ—¶ä½¿ç”¨"""
        print("âš ï¸ Agent2ç»“æœç¼ºå¤±ï¼Œä½¿ç”¨åŸºç¡€æ¨¡å¼")
        # ç®€åŒ–çš„AIåˆ†æé€»è¾‘
        return {
            "device_allocations": {},
            "analysis_summary": {"analyzed_devices": 0, "confidence_scores": []},
        }

    def _perform_basic_comparison(
        self, existing_data: Dict, ai_data: Dict
    ) -> Dict[str, Any]:
        """æ‰§è¡ŒåŸºç¡€å¯¹æ¯”åˆ†æï¼Œå½“Agent3ç»“æœä¸å­˜åœ¨æ—¶ä½¿ç”¨"""
        print("âš ï¸ Agent3ç»“æœç¼ºå¤±ï¼Œä½¿ç”¨åŸºç¡€æ¨¡å¼")
        return {
            "comparison_results": [],
            "overall_match_rate": "N/A",
            "device_analysis": {},
        }

    def prepare_device_mappings_from_real_data(self) -> Dict[str, Any]:
        """å¤‡ç”¨æ–¹æ³•ï¼šå‡†å¤‡è®¾å¤‡æ˜ å°„æ•°æ®"""
        print("âš ï¸ ä½¿ç”¨ç©ºçš„è®¾å¤‡æ˜ å°„æ•°æ®")
        return {}

    def load_official_documentation(self, doc_path: str) -> Dict[str, List[str]]:
        """å¤‡ç”¨æ–¹æ³•ï¼šåŠ è½½å®˜æ–¹æ–‡æ¡£"""
        print("âš ï¸ è·³è¿‡å®˜æ–¹æ–‡æ¡£åŠ è½½")
        return {}

    def _apply_smart_filtering(self, comparison_data: Dict) -> Dict[str, Any]:
        """
        åº”ç”¨æ™ºèƒ½è¿‡æ»¤ï¼šç§»é™¤100%åŒ¹é…è®¾å¤‡ï¼Œèšç„¦å·®å¼‚è®¾å¤‡

        Args:
            comparison_data: å¯¹æ¯”åˆ†ææ•°æ®

        Returns:
            è¿‡æ»¤åçš„ç»“æœæ•°æ®
        """
        device_analysis = comparison_data.get("device_analysis", {})

        for device_name, analysis in device_analysis.items():
            confidence_score = analysis.get("confidence_score", 0.0)
            match_type = analysis.get("match_type", "unknown")

            if (
                confidence_score >= self.confidence_threshold
                and match_type == "å®Œå…¨åŒ¹é…"
            ):
                # é«˜ç½®ä¿¡åº¦å®Œå…¨åŒ¹é…è®¾å¤‡ - è¿‡æ»¤æ‰
                self.filtered_devices.append(
                    {
                        "device_name": device_name,
                        "confidence_score": confidence_score,
                        "match_type": match_type,
                        "reason": "é«˜ç½®ä¿¡åº¦å®Œå…¨åŒ¹é…ï¼Œæ— éœ€AI Tokenåˆ†æ",
                    }
                )
            else:
                # éœ€è¦å…³æ³¨çš„å·®å¼‚è®¾å¤‡
                self.focus_devices.append(
                    {
                        "device_name": device_name,
                        "confidence_score": confidence_score,
                        "match_type": match_type,
                        "priority": self._calculate_priority(
                            confidence_score, match_type
                        ),
                        "analysis_details": analysis,
                    }
                )

        # æŒ‰ä¼˜å…ˆçº§æ’åºéœ€è¦å…³æ³¨çš„è®¾å¤‡
        self.focus_devices.sort(key=lambda x: x["priority"], reverse=True)

        return {
            "filtered_count": len(self.filtered_devices),
            "focus_count": len(self.focus_devices),
            "filtered_devices": self.filtered_devices,
            "focus_devices": self.focus_devices,
        }

    def _calculate_priority(self, confidence_score: float, match_type: str) -> int:
        """
        è®¡ç®—è®¾å¤‡ä¼˜å…ˆçº§åˆ†æ•°ï¼ˆè¶Šé«˜è¶Šéœ€è¦å…³æ³¨ï¼‰

        Args:
            confidence_score: ç½®ä¿¡åº¦åˆ†æ•°
            match_type: åŒ¹é…ç±»å‹

        Returns:
            ä¼˜å…ˆçº§åˆ†æ•° (0-100)
        """
        base_priority = 0

        # æ ¹æ®åŒ¹é…ç±»å‹ç¡®å®šåŸºç¡€ä¼˜å…ˆçº§
        if match_type == "å®Œå…¨ä¸åŒ¹é…":
            base_priority = 90
        elif match_type == "éƒ¨åˆ†åŒ¹é…":
            base_priority = 60
        elif match_type == "AIç‹¬æœ‰å»ºè®®":
            base_priority = 40
        elif match_type == "ç°æœ‰ç‹¬æœ‰åˆ†é…":
            base_priority = 30
        else:
            base_priority = 20

        # æ ¹æ®ç½®ä¿¡åº¦è°ƒæ•´ä¼˜å…ˆçº§ (ç½®ä¿¡åº¦è¶Šä½ï¼Œä¼˜å…ˆçº§è¶Šé«˜)
        confidence_adjustment = int((1.0 - confidence_score) * 20)

        final_priority = min(100, base_priority + confidence_adjustment)
        return final_priority

    def _generate_smart_report(
        self, filtered_results: Dict, existing_data: Dict, ai_data: Dict
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆæ™ºèƒ½èšç„¦æŠ¥å‘Š - ç§»é™¤æ— ç”¨ä¿¡æ¯ï¼Œä¸“æ³¨å·®å¼‚è®¾å¤‡

        Args:
            filtered_results: æ™ºèƒ½è¿‡æ»¤ç»“æœ
            existing_data: ç°æœ‰åˆ†é…æ•°æ®
            ai_data: AIåˆ†ææ•°æ®

        Returns:
            æ™ºèƒ½æŠ¥å‘Šå­—å…¸
        """
        focus_devices = filtered_results.get("focus_devices", [])
        filtered_devices = filtered_results.get("filtered_devices", [])

        # è®¡ç®—TokenèŠ‚çœç»Ÿè®¡
        total_devices = len(focus_devices) + len(filtered_devices)
        token_savings_rate = (
            (len(filtered_devices) / total_devices * 100) if total_devices > 0 else 0
        )

        # åˆ†ç±»éœ€è¦å…³æ³¨çš„è®¾å¤‡
        high_priority = [d for d in focus_devices if d["priority"] >= 80]
        medium_priority = [d for d in focus_devices if 50 <= d["priority"] < 80]
        low_priority = [d for d in focus_devices if d["priority"] < 50]

        smart_report = {
            "åˆ†ææ¦‚è§ˆ": {
                "ç”Ÿæˆæ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "å·¥å…·ç‰ˆæœ¬": "RUN_THIS_TOOL.py v4.0 (æ™ºèƒ½è¿‡æ»¤ç‰ˆ)",
                "åˆ†ææ¨¡å¼": "æ™ºèƒ½IOåˆ†é…å¯¹æ¯” (ä¸“æ³¨å·®å¼‚è®¾å¤‡)",
                "æ€»è®¾å¤‡æ•°": total_devices,
                "éœ€è¦å…³æ³¨è®¾å¤‡æ•°": len(focus_devices),
                "å·²è¿‡æ»¤è®¾å¤‡æ•°": len(filtered_devices),
                "AI TokenèŠ‚çœç‡": f"{token_savings_rate:.1f}%",
                "ç½®ä¿¡åº¦é˜ˆå€¼": self.confidence_threshold,
            },
            "æ™ºèƒ½è¿‡æ»¤ç»“æœ": {
                "è¿‡æ»¤ç­–ç•¥": "è‡ªåŠ¨è¿‡æ»¤100%åŒ¹é…ä¸”é«˜ç½®ä¿¡åº¦è®¾å¤‡",
                "èŠ‚çœçš„AI Token": len(filtered_devices),
                "èšç„¦çš„å·®å¼‚è®¾å¤‡": len(focus_devices),
                "è¿‡æ»¤è®¾å¤‡åˆ—è¡¨": [
                    d["device_name"] for d in filtered_devices[:10]
                ],  # åªæ˜¾ç¤ºå‰10ä¸ª
            },
            "å·®å¼‚è®¾å¤‡åˆ†æ": {
                "é«˜ä¼˜å…ˆçº§è®¾å¤‡": {
                    "æ•°é‡": len(high_priority),
                    "è¯´æ˜": "éœ€è¦ç«‹å³å…³æ³¨çš„å…³é”®å·®å¼‚",
                    "è®¾å¤‡åˆ—è¡¨": [
                        {
                            "è®¾å¤‡å": d["device_name"],
                            "ç½®ä¿¡åº¦": d["confidence_score"],
                            "ç±»å‹": d["match_type"],
                        }
                        for d in high_priority[:5]
                    ],
                },
                "ä¸­ä¼˜å…ˆçº§è®¾å¤‡": {
                    "æ•°é‡": len(medium_priority),
                    "è¯´æ˜": "å»ºè®®ä¼˜åŒ–çš„ä¸­ç­‰å·®å¼‚",
                    "è®¾å¤‡åˆ—è¡¨": [
                        {
                            "è®¾å¤‡å": d["device_name"],
                            "ç½®ä¿¡åº¦": d["confidence_score"],
                            "ç±»å‹": d["match_type"],
                        }
                        for d in medium_priority[:5]
                    ],
                },
                "ä½ä¼˜å…ˆçº§è®¾å¤‡": {
                    "æ•°é‡": len(low_priority),
                    "è¯´æ˜": "å¯é€‰æ”¹è¿›çš„è½»å¾®å·®å¼‚",
                    "è®¾å¤‡åˆ—è¡¨": [
                        {
                            "è®¾å¤‡å": d["device_name"],
                            "ç½®ä¿¡åº¦": d["confidence_score"],
                            "ç±»å‹": d["match_type"],
                        }
                        for d in low_priority[:5]
                    ],
                },
            },
            "æ ¸å¿ƒå‘ç°": self._extract_key_insights(focus_devices),
            "è¡ŒåŠ¨å»ºè®®": self._generate_actionable_recommendations(
                high_priority, medium_priority
            ),
            "åŠŸèƒ½çŠ¶æ€": {
                "æ™ºèƒ½è¿‡æ»¤": "âœ… å·²å¯ç”¨",
                "å·®å¼‚èšç„¦": "âœ… å·²å¯ç”¨",
                "TokenèŠ‚çœ": "âœ… å·²å¯ç”¨",
                "ç½®ä¿¡åº¦è¯„ä¼°": "âœ… å·²å¯ç”¨",
                "å¤šAgentåä½œ": "âœ… å·²å¯ç”¨",
                "æ— ç”¨æŠ¥å‘Šç§»é™¤": "âœ… å¤šIOè®¾å¤‡å’ŒBitmaskæŠ¥å‘Šå·²ç§»é™¤",
            },
        }

        return smart_report

    def _extract_key_insights(self, focus_devices: List[Dict]) -> Dict[str, Any]:
        """ä»å…³æ³¨è®¾å¤‡ä¸­æå–å…³é”®æ´å¯Ÿ"""
        if not focus_devices:
            return {"çŠ¶æ€": "æ‰€æœ‰è®¾å¤‡åŒ¹é…åº¦è‰¯å¥½ï¼Œæ— éœ€ç‰¹æ®Šå…³æ³¨"}

        # ç»Ÿè®¡åŒ¹é…ç±»å‹åˆ†å¸ƒ
        match_type_counts = {}
        confidence_scores = []

        for device in focus_devices:
            match_type = device["match_type"]
            match_type_counts[match_type] = match_type_counts.get(match_type, 0) + 1
            confidence_scores.append(device["confidence_score"])

        avg_confidence = (
            sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0
        )

        return {
            "å·®å¼‚ç±»å‹åˆ†å¸ƒ": match_type_counts,
            "å¹³å‡ç½®ä¿¡åº¦": round(avg_confidence, 3),
            "æœ€éœ€å…³æ³¨è®¾å¤‡": focus_devices[0]["device_name"] if focus_devices else "æ— ",
            "ä¸»è¦é—®é¢˜ç±»å‹": (
                max(match_type_counts.items(), key=lambda x: x[1])[0]
                if match_type_counts
                else "æ— "
            ),
        }

    def _generate_actionable_recommendations(
        self, high_priority: List, medium_priority: List
    ) -> List[Dict]:
        """ç”Ÿæˆå¯æ‰§è¡Œçš„è¡ŒåŠ¨å»ºè®®"""
        recommendations = []

        # é«˜ä¼˜å…ˆçº§è®¾å¤‡å»ºè®®
        for device in high_priority[:3]:  # åªå¤„ç†å‰3ä¸ªæœ€é‡è¦çš„
            rec = {
                "è®¾å¤‡å": device["device_name"],
                "ä¼˜å…ˆçº§": "ğŸ”´ é«˜",
                "ç½®ä¿¡åº¦": device["confidence_score"],
                "é—®é¢˜ç±»å‹": device["match_type"],
                "å»ºè®®è¡ŒåŠ¨": self._get_specific_recommendation(device),
                "é¢„è®¡å·¥ä½œé‡": "2-4å°æ—¶",
            }
            recommendations.append(rec)

        # ä¸­ä¼˜å…ˆçº§è®¾å¤‡å»ºè®®
        for device in medium_priority[:2]:  # åªå¤„ç†å‰2ä¸ª
            rec = {
                "è®¾å¤‡å": device["device_name"],
                "ä¼˜å…ˆçº§": "ğŸŸ¡ ä¸­",
                "ç½®ä¿¡åº¦": device["confidence_score"],
                "é—®é¢˜ç±»å‹": device["match_type"],
                "å»ºè®®è¡ŒåŠ¨": self._get_specific_recommendation(device),
                "é¢„è®¡å·¥ä½œé‡": "1-2å°æ—¶",
            }
            recommendations.append(rec)

        return recommendations

    def _get_specific_recommendation(self, device: Dict) -> str:
        """æ ¹æ®è®¾å¤‡æƒ…å†µç”Ÿæˆå…·ä½“å»ºè®®"""
        match_type = device["match_type"]
        confidence = device["confidence_score"]

        if match_type == "å®Œå…¨ä¸åŒ¹é…":
            return "å®Œæ•´é‡æ–°è®¾è®¡IOåˆ†é…æ–¹æ¡ˆ"
        elif match_type == "éƒ¨åˆ†åŒ¹é…":
            if confidence < 0.5:
                return "é‡ç‚¹å®¡æŸ¥å·®å¼‚å¹³å°ï¼ŒéªŒè¯åŠŸèƒ½å®Œæ•´æ€§"
            else:
                return "å¾®è°ƒå¹³å°åˆ†é…ï¼Œå¯¹é½AIå»ºè®®"
        elif match_type == "AIç‹¬æœ‰å»ºè®®":
            return "è¯„ä¼°AIå»ºè®®çš„å¿…è¦æ€§ï¼Œè€ƒè™‘é‡‡çº³"
        elif match_type == "ç°æœ‰ç‹¬æœ‰åˆ†é…":
            return "éªŒè¯ç°æœ‰åˆ†é…çš„åˆç†æ€§ï¼Œè€ƒè™‘ç§»é™¤å†—ä½™"
        else:
            return "æ·±å…¥åˆ†æå·®å¼‚åŸå› ï¼Œåˆ¶å®šé’ˆå¯¹æ€§æ–¹æ¡ˆ"

    def _enhance_report_with_ai_analysis(
        self, report: Dict[str, Any], analysis_results: List[EnhancedAnalysisResult]
    ) -> Dict[str, Any]:
        """å¢å¼ºæŠ¥å‘Šä»¥åŒ…å«çº¯AIåˆ†æä¿¡æ¯"""

        # ç»Ÿè®¡AIåˆ†æç»“æœ
        ai_analyzed_devices = [r for r in analysis_results if r.ai_analysis_result]
        multi_io_devices = [r for r in analysis_results if r.is_multi_io_device]
        bitmask_devices = [r for r in analysis_results if r.bitmask_ios]
        multi_platform_devices = [r for r in analysis_results if r.multi_platform_ios]

        # ç½®ä¿¡åº¦ç»Ÿè®¡
        if ai_analyzed_devices:
            avg_ai_confidence = sum(
                r.ai_analysis_result.analysis_confidence for r in ai_analyzed_devices
            ) / len(ai_analyzed_devices)
            high_confidence_devices = [
                r
                for r in ai_analyzed_devices
                if r.ai_analysis_result.analysis_confidence >= 0.8
            ]
        else:
            avg_ai_confidence = 0.0
            high_confidence_devices = []

        # æ·»åŠ çº¯AIåˆ†æéƒ¨åˆ†åˆ°æŠ¥å‘Š
        report["çº¯AIåˆ†æç»“æœ"] = {
            "AIåˆ†æè®¾å¤‡æ•°": len(ai_analyzed_devices),
            "å¤šIOè®¾å¤‡æ•°": len(multi_io_devices),
            "Bitmaskè®¾å¤‡æ•°": len(bitmask_devices),
            "å¤šå¹³å°åˆ†é…è®¾å¤‡æ•°": len(multi_platform_devices),
            "å¹³å‡AIç½®ä¿¡åº¦": round(avg_ai_confidence, 3),
            "é«˜ç½®ä¿¡åº¦è®¾å¤‡æ•°": len(high_confidence_devices),
            "å¤šIOè®¾å¤‡åˆ—è¡¨": [r.device_name for r in multi_io_devices],
            "Bitmaskè®¾å¤‡åˆ—è¡¨": [r.device_name for r in bitmask_devices],
            "å¤šå¹³å°åˆ†é…è®¾å¤‡åˆ—è¡¨": [r.device_name for r in multi_platform_devices],
        }

        # å¢å¼ºè¯¦ç»†ç»“æœä»¥åŒ…å«AIåˆ†æå­—æ®µ
        for detail in report["è¯¦ç»†ç»“æœ"]:
            device_name = detail["è®¾å¤‡åç§°"]
            matching_result = next(
                (r for r in analysis_results if r.device_name == device_name), None
            )

            if matching_result:
                detail["æ˜¯å¦å¤šIOè®¾å¤‡"] = matching_result.is_multi_io_device
                detail["Bitmask IOæ•°é‡"] = len(matching_result.bitmask_ios or [])
                detail["å¤šå¹³å°IOæ•°é‡"] = len(matching_result.multi_platform_ios or [])
                detail["AIåˆ†æç½®ä¿¡åº¦"] = (
                    round(matching_result.ai_analysis_result.analysis_confidence, 3)
                    if matching_result.ai_analysis_result
                    else 0.0
                )

        return report

    def _perform_documentation_validation(
        self,
        doc_ios_map: Dict[str, List[str]],
        device_mappings: Dict[str, Any],
        analysis_results: List[EnhancedAnalysisResult],
    ) -> Dict[str, Any]:
        """æ‰§è¡Œå®˜æ–¹æ–‡æ¡£éªŒè¯å¯¹æ¯”"""

        # ç»Ÿè®¡åˆ†æ
        doc_device_count = len(doc_ios_map)
        mapping_device_count = len(device_mappings)

        # IOå£æ•°é‡ç»Ÿè®¡ - ä¿®å¤è®¡ç®—é€»è¾‘
        total_doc_ios = sum(len(ios) for ios in doc_ios_map.values())
        total_mapping_ios = sum(len(result.mapped_ios) for result in analysis_results)

        # è®¾å¤‡è¦†ç›–ç‡åˆ†æ
        doc_devices = set(doc_ios_map.keys())
        mapping_devices = set(device_mappings.keys())

        covered_devices = doc_devices & mapping_devices
        missing_in_mapping = doc_devices - mapping_devices
        extra_in_mapping = mapping_devices - doc_devices

        coverage_rate = len(covered_devices) / len(doc_devices) if doc_devices else 0

        return {
            "è®¾å¤‡æ•°é‡å¯¹æ¯”": {
                "å®˜æ–¹æ–‡æ¡£è®¾å¤‡æ•°": doc_device_count,
                "æ˜ å°„é…ç½®è®¾å¤‡æ•°": mapping_device_count,
                "è¦†ç›–è®¾å¤‡æ•°": len(covered_devices),
                "è®¾å¤‡è¦†ç›–ç‡": f"{coverage_rate:.1%}",
            },
            "IOå£æ•°é‡å¯¹æ¯”": {
                "å®˜æ–¹æ–‡æ¡£IOå£æ€»æ•°": total_doc_ios,
                "æ˜ å°„é…ç½®IOå£æ€»æ•°": total_mapping_ios,
                "IOå£åŒ¹é…ç‡": (
                    f"{(total_mapping_ios/total_doc_ios):.1%}"
                    if total_doc_ios > 0
                    else "0%"
                ),
            },
            "è®¾å¤‡è¦†ç›–åˆ†æ": {
                "å·²è¦†ç›–è®¾å¤‡": list(covered_devices),
                "æ–‡æ¡£ä¸­ç¼ºå¤±çš„è®¾å¤‡": list(missing_in_mapping),
                "æ˜ å°„ä¸­é¢å¤–çš„è®¾å¤‡": list(extra_in_mapping),
            },
        }

    def _generate_comprehensive_report(
        self,
        analysis_results: List[EnhancedAnalysisResult],
        validation_results: Dict[str, Any],
        doc_ios_map: Dict[str, List[str]],
        device_mappings: Dict[str, Any],
    ) -> Dict[str, Any]:
        """ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š"""

        # åŸºç¡€ç»Ÿè®¡
        total_devices = len(analysis_results)
        problem_devices = [r for r in analysis_results if r.match_score < 0.9]
        excellent_devices = [r for r in analysis_results if r.match_score >= 0.9]

        # å¹³å°åˆ†é…é—®é¢˜ç»Ÿè®¡
        platform_issues = [r for r in analysis_results if r.platform_allocation_issues]

        # ç”Ÿæˆæ¦‚è§ˆ
        analysis_overview = {
            "ç”Ÿæˆæ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "å·¥å…·ç‰ˆæœ¬": "RUN_THIS_TOOL.py v3.0 (å®Œæ•´ç‰ˆ)",
            "åˆ†ææ¨¡å¼": "åŒé‡éªŒè¯æœºåˆ¶ (çº¯AIåˆ†æ + å®˜æ–¹æ–‡æ¡£éªŒè¯)",
            "æ”¯æŒå¹³å°æ•°": len(self.supported_platforms),
            "æ€»è®¾å¤‡æ•°": total_devices,
            "ä¼˜ç§€è®¾å¤‡æ•°": len(excellent_devices),
            "é—®é¢˜è®¾å¤‡æ•°": len(problem_devices),
            "å¹³å°åˆ†é…é—®é¢˜è®¾å¤‡": len(platform_issues),
            "æ•´ä½“åŒ¹é…ç‡": (
                f"{(len(excellent_devices)/total_devices*100):.1f}%"
                if total_devices > 0
                else "0%"
            ),
        }

        # é—®é¢˜è®¾å¤‡åˆ†æ
        problem_analysis = self._analyze_problem_devices(problem_devices)

        # æ”¹è¿›å»ºè®®
        improvement_suggestions = self._generate_improvement_suggestions(
            problem_devices
        )

        # åŠŸèƒ½çŠ¶æ€
        feature_status = {
            "çº¯AIåˆ†æ": "âœ… å·²å¯ç”¨",
            "å®˜æ–¹æ–‡æ¡£è§£æ": "âœ… å·²å¯ç”¨",
            "åŒé‡éªŒè¯æœºåˆ¶": "âœ… å·²å¯ç”¨",
            "IOå£é€»è¾‘åˆ†æ": "âœ… å·²å¯ç”¨",
            "å¹³å°åˆ†é…éªŒè¯": "âœ… å·²å¯ç”¨",
            "Bitmaskæ£€æµ‹": "âœ… å·²å¯ç”¨",
            "å¤šå¹³å°åˆ†é…": "âœ… å·²å¯ç”¨",
            "æ€§èƒ½ç›‘æ§": "âœ… å·²å¯ç”¨",
            "æ”¯æŒçš„å¹³å°": list(self.supported_platforms),
        }

        return {
            "åˆ†ææ¦‚è§ˆ": analysis_overview,
            "å®˜æ–¹æ–‡æ¡£éªŒè¯": validation_results,
            "é—®é¢˜è®¾å¤‡åˆ†æ": problem_analysis,
            "æ”¹è¿›å»ºè®®": improvement_suggestions,
            "åŠŸèƒ½çŠ¶æ€": feature_status,
            "è¯¦ç»†ç»“æœ": [
                {
                    "è®¾å¤‡åç§°": r.device_name,
                    "åŒ¹é…åˆ†æ•°": round(r.match_score, 3),
                    "å¹³å°åˆ†é…åˆ†æ•°": round(r.platform_allocation_score, 3),
                    "åˆ†æç­–ç•¥": r.analysis_type,
                    "æ–‡æ¡£IOå£": list(r.doc_ios),
                    "æ˜ å°„IOå£": list(r.mapped_ios),
                    "å¹³å°åˆ†é…é—®é¢˜": len(r.platform_allocation_issues or []),
                }
                for r in analysis_results
                # åŒ…å«æ‰€æœ‰è®¾å¤‡çš„è¯¦ç»†ç»“æœï¼Œè€Œä¸ä»…ä»…æ˜¯é—®é¢˜è®¾å¤‡
            ],
        }

    def _analyze_problem_devices(
        self, problem_devices: List[EnhancedAnalysisResult]
    ) -> Dict[str, Any]:
        """åˆ†æé—®é¢˜è®¾å¤‡"""
        # æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†ç»„
        critical_devices = [r for r in problem_devices if r.match_score == 0]
        major_issues = [r for r in problem_devices if 0 < r.match_score < 0.5]
        minor_issues = [r for r in problem_devices if 0.5 <= r.match_score < 0.9]

        return {
            "å…³é”®é—®é¢˜è®¾å¤‡": {
                "æ•°é‡": len(critical_devices),
                "è¯´æ˜": "å®Œå…¨ä¸åŒ¹é…ï¼Œéœ€è¦ç«‹å³ä¿®å¤",
                "è®¾å¤‡åˆ—è¡¨": [r.device_name for r in critical_devices],
            },
            "ä¸¥é‡é—®é¢˜è®¾å¤‡": {
                "æ•°é‡": len(major_issues),
                "è¯´æ˜": "åŒ¹é…åº¦å¾ˆä½ï¼Œéœ€è¦é‡ç‚¹å…³æ³¨",
                "è®¾å¤‡åˆ—è¡¨": [r.device_name for r in major_issues],
            },
            "è½»å¾®é—®é¢˜è®¾å¤‡": {
                "æ•°é‡": len(minor_issues),
                "è¯´æ˜": "éƒ¨åˆ†åŒ¹é…ï¼Œéœ€è¦å®Œå–„",
                "è®¾å¤‡åˆ—è¡¨": [r.device_name for r in minor_issues],
            },
        }

    def _generate_improvement_suggestions(
        self, problem_devices: List[EnhancedAnalysisResult]
    ) -> List[Dict[str, Any]]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        suggestions = []

        # æŒ‰åŒ¹é…åˆ†æ•°æ’åºï¼Œä¼˜å…ˆæ˜¾ç¤ºæœ€ä¸¥é‡çš„é—®é¢˜
        problem_devices.sort(key=lambda x: x.match_score)

        for result in problem_devices[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ªæœ€éœ€è¦å…³æ³¨çš„
            suggestion = {
                "è®¾å¤‡åç§°": result.device_name,
                "å½“å‰åˆ†æ•°": round(result.match_score, 3),
                "å¹³å°åˆ†é…åˆ†æ•°": round(result.platform_allocation_score, 3),
                "ä¼˜å…ˆçº§": self._get_priority_level(result.match_score),
                "é—®é¢˜ç±»å‹": [],
                "å…·ä½“å»ºè®®": [],
            }

            # åˆ†æé—®é¢˜ç±»å‹å’Œå»ºè®®
            if result.unmatched_doc:
                suggestion["é—®é¢˜ç±»å‹"].append("ç¼ºå¤±æ˜ å°„IOå£")
                suggestion["å…·ä½“å»ºè®®"].append(
                    f"éœ€è¦æ·»åŠ ä»¥ä¸‹IOå£çš„æ˜ å°„: {', '.join(result.unmatched_doc)}"
                )

            if result.unmatched_mapping:
                suggestion["é—®é¢˜ç±»å‹"].append("å¤šä½™æ˜ å°„IOå£")
                suggestion["å…·ä½“å»ºè®®"].append(
                    f"ä»¥ä¸‹IOå£åœ¨æ–‡æ¡£ä¸­æ‰¾ä¸åˆ°å¯¹åº”: {', '.join(result.unmatched_mapping)}"
                )

            if result.platform_allocation_issues:
                suggestion["é—®é¢˜ç±»å‹"].append("å¹³å°åˆ†é…é—®é¢˜")
                suggestion["å…·ä½“å»ºè®®"].append(
                    f"æ£€æµ‹åˆ° {len(result.platform_allocation_issues)} ä¸ªå¹³å°åˆ†é…é—®é¢˜"
                )

            suggestions.append(suggestion)

        return suggestions

    def _get_priority_level(self, score: float) -> str:
        """æ ¹æ®åŒ¹é…åˆ†æ•°ç¡®å®šä¼˜å…ˆçº§"""
        if score == 0:
            return "ğŸ”´ ç´§æ€¥"
        elif score < 0.5:
            return "ğŸŸ  é«˜"
        elif score < 0.9:
            return "ğŸŸ¡ ä¸­"
        else:
            return "ğŸŸ¢ ä½"

    def save_analysis_report(self, report: Dict[str, Any], output_path: str):
        """ä¿å­˜åˆ†ææŠ¥å‘Šåˆ°æ–‡ä»¶"""
        import json

        try:
            with open(output_path, "w", encoding="utf-8") as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            print(f"âœ… JSONåˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")
        except Exception as e:
            print(f"âŒ ä¿å­˜JSONæŠ¥å‘Šå¤±è´¥: {e}")

    def generate_smart_markdown_report(self, report: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ™ºèƒ½èšç„¦çš„MarkdownæŠ¥å‘Š - ç§»é™¤æ— ç”¨ä¿¡æ¯"""
        md_content = []

        # æ ‡é¢˜å’ŒåŸºæœ¬ä¿¡æ¯
        md_content.append("# ğŸ¯ æ™ºèƒ½IOåˆ†é…å¯¹æ¯”åˆ†ææŠ¥å‘Š")
        md_content.append("")
        md_content.append(f"**ç”Ÿæˆæ—¶é—´**: {report['åˆ†ææ¦‚è§ˆ']['ç”Ÿæˆæ—¶é—´']}")
        md_content.append(f"**å·¥å…·ç‰ˆæœ¬**: {report['åˆ†ææ¦‚è§ˆ']['å·¥å…·ç‰ˆæœ¬']}")
        md_content.append(f"**åˆ†ææ¨¡å¼**: {report['åˆ†ææ¦‚è§ˆ']['åˆ†ææ¨¡å¼']}")
        md_content.append(
            "**æ ¸å¿ƒç‰¹è‰²**: ğŸ¯ ä¸“æ³¨å·®å¼‚è®¾å¤‡ | ğŸš« æ— ç”¨æŠ¥å‘Šå·²ç§»é™¤ | ğŸ’° æ™ºèƒ½TokenèŠ‚çœ"
        )
        md_content.append("")
        md_content.append("---")
        md_content.append("")

        # åˆ†ææ¦‚è§ˆ
        overview = report["åˆ†ææ¦‚è§ˆ"]
        md_content.append("## ğŸ“Š æ ¸å¿ƒç»Ÿè®¡")
        md_content.append("")
        md_content.append("| æŒ‡æ ‡ | æ•°å€¼ | è¯´æ˜ |")
        md_content.append("|------|------|------|")
        md_content.append(f"| **æ€»è®¾å¤‡æ•°** | {overview['æ€»è®¾å¤‡æ•°']}ä¸ª | åˆ†æè¦†ç›–è®¾å¤‡ |")
        md_content.append(
            f"| **éœ€è¦å…³æ³¨è®¾å¤‡** | {overview['éœ€è¦å…³æ³¨è®¾å¤‡æ•°']}ä¸ª | å­˜åœ¨å·®å¼‚çš„è®¾å¤‡ |"
        )
        md_content.append(
            f"| **å·²è¿‡æ»¤è®¾å¤‡** | {overview['å·²è¿‡æ»¤è®¾å¤‡æ•°']}ä¸ª | 100%åŒ¹é…çš„è®¾å¤‡ |"
        )
        md_content.append(
            f"| **AI TokenèŠ‚çœç‡** | {overview['AI TokenèŠ‚çœç‡']} | æ™ºèƒ½è¿‡æ»¤æ•ˆæœ |"
        )
        md_content.append("")

        # æ™ºèƒ½è¿‡æ»¤ç»“æœ
        filtering = report["æ™ºèƒ½è¿‡æ»¤ç»“æœ"]
        md_content.append("## ğŸ¤– æ™ºèƒ½è¿‡æ»¤æˆæ•ˆ")
        md_content.append("")
        md_content.append(f"- **è¿‡æ»¤ç­–ç•¥**: {filtering['è¿‡æ»¤ç­–ç•¥']}")
        md_content.append(f"- **èŠ‚çœAI Token**: {filtering['èŠ‚çœçš„AI Token']}ä¸ªè®¾å¤‡")
        md_content.append(f"- **èšç„¦å·®å¼‚è®¾å¤‡**: {filtering['èšç„¦çš„å·®å¼‚è®¾å¤‡']}ä¸ªè®¾å¤‡")
        md_content.append("")

        if filtering.get("è¿‡æ»¤è®¾å¤‡åˆ—è¡¨"):
            md_content.append("**è¢«è¿‡æ»¤çš„é«˜åŒ¹é…åº¦è®¾å¤‡** (å‰10ä¸ª):")
            for device in filtering["è¿‡æ»¤è®¾å¤‡åˆ—è¡¨"]:
                md_content.append(f"- `{device}` âœ…")
            md_content.append("")

        # å·®å¼‚è®¾å¤‡åˆ†æ - åªæ˜¾ç¤ºæœ‰å·®å¼‚çš„è®¾å¤‡
        diff_analysis = report["å·®å¼‚è®¾å¤‡åˆ†æ"]
        md_content.append("## ğŸ” éœ€è¦å…³æ³¨çš„å·®å¼‚è®¾å¤‡")
        md_content.append("")

        for priority_level, info in diff_analysis.items():
            if info["æ•°é‡"] > 0:
                icon = (
                    "ğŸ”´"
                    if "é«˜ä¼˜å…ˆçº§" in priority_level
                    else "ğŸŸ¡" if "ä¸­ä¼˜å…ˆçº§" in priority_level else "ğŸŸ¢"
                )
                md_content.append(f"### {icon} {priority_level} ({info['æ•°é‡']}ä¸ª)")
                md_content.append(f"*{info['è¯´æ˜']}*")
                md_content.append("")

                for device in info["è®¾å¤‡åˆ—è¡¨"]:
                    md_content.append(
                        f"- **{device['è®¾å¤‡å']}**: ç½®ä¿¡åº¦ {device['ç½®ä¿¡åº¦']:.3f}, ç±»å‹: {device['ç±»å‹']}"
                    )

                md_content.append("")

        # æ ¸å¿ƒå‘ç°
        insights = report["æ ¸å¿ƒå‘ç°"]
        md_content.append("## ğŸ’¡ æ ¸å¿ƒå‘ç°")
        md_content.append("")

        if insights.get("çŠ¶æ€"):
            md_content.append(f"ğŸ‰ **{insights['çŠ¶æ€']}**")
        else:
            md_content.append(
                f"- **ä¸»è¦é—®é¢˜ç±»å‹**: {insights.get('ä¸»è¦é—®é¢˜ç±»å‹', 'N/A')}"
            )
            md_content.append(f"- **å¹³å‡ç½®ä¿¡åº¦**: {insights.get('å¹³å‡ç½®ä¿¡åº¦', 'N/A')}")
            md_content.append(
                f"- **æœ€éœ€å…³æ³¨è®¾å¤‡**: `{insights.get('æœ€éœ€å…³æ³¨è®¾å¤‡', 'N/A')}`"
            )
            md_content.append("")

            if insights.get("å·®å¼‚ç±»å‹åˆ†å¸ƒ"):
                md_content.append("**å·®å¼‚ç±»å‹åˆ†å¸ƒ**:")
                for diff_type, count in insights["å·®å¼‚ç±»å‹åˆ†å¸ƒ"].items():
                    md_content.append(f"- {diff_type}: {count}ä¸ª")

        md_content.append("")

        # è¡ŒåŠ¨å»ºè®®
        recommendations = report["è¡ŒåŠ¨å»ºè®®"]
        if recommendations:
            md_content.append("## ğŸ¯ ç«‹å³è¡ŒåŠ¨å»ºè®®")
            md_content.append("")

            for i, rec in enumerate(recommendations, 1):
                md_content.append(f"### {i}. {rec['è®¾å¤‡å']} - {rec['ä¼˜å…ˆçº§']}")
                md_content.append(f"**é—®é¢˜ç±»å‹**: {rec['é—®é¢˜ç±»å‹']}")
                md_content.append(f"**ç½®ä¿¡åº¦**: {rec['ç½®ä¿¡åº¦']:.3f}")
                md_content.append(f"**å»ºè®®è¡ŒåŠ¨**: {rec['å»ºè®®è¡ŒåŠ¨']}")
                md_content.append(f"**é¢„è®¡å·¥ä½œé‡**: {rec['é¢„è®¡å·¥ä½œé‡']}")
                md_content.append("")

        # åŠŸèƒ½çŠ¶æ€è¯´æ˜
        md_content.append("## âœ… å‡çº§åŠŸèƒ½è¯´æ˜")
        md_content.append("")
        feature_status = report["åŠŸèƒ½çŠ¶æ€"]
        for feature, status in feature_status.items():
            md_content.append(f"- **{feature}**: {status}")
        md_content.append("")

        md_content.append("---")
        md_content.append("")
        md_content.append("## ğŸ“‹ é‡è¦è¯´æ˜")
        md_content.append("")
        md_content.append("### ğŸ¯ å‡çº§äº®ç‚¹")
        md_content.append("1. **ä¸“æ³¨å·®å¼‚**: åªå…³æ³¨éœ€è¦äººå·¥å¹²é¢„çš„ä¸ä¸€è‡´è®¾å¤‡")
        md_content.append("2. **æ™ºèƒ½è¿‡æ»¤**: è‡ªåŠ¨è¿‡æ»¤100%åŒ¹é…çš„é«˜ç½®ä¿¡åº¦è®¾å¤‡")
        md_content.append("3. **TokenèŠ‚çœ**: é¿å…å¯¹å®Œç¾åŒ¹é…è®¾å¤‡æµªè´¹AIèµ„æº")
        md_content.append(
            "4. **æ— ç”¨ä¿¡æ¯ç§»é™¤**: ä¸å†æ˜¾ç¤ºå¤šIOè®¾å¤‡å’ŒBitmaskè®¾å¤‡ç­‰æ— å…³ä¿¡æ¯"
        )
        md_content.append("")
        md_content.append("### ğŸš« å·²ç§»é™¤çš„æ— ç”¨æŠ¥å‘Š")
        md_content.append("- âŒ å¤šIOè®¾å¤‡åˆ—è¡¨ (ä¸æ ¸å¿ƒéœ€æ±‚æ— å…³)")
        md_content.append("- âŒ Bitmaskè®¾å¤‡æŠ¥å‘Š (ä¸æ ¸å¿ƒéœ€æ±‚æ— å…³)")
        md_content.append("- âŒ 100%åŒ¹é…è®¾å¤‡çš„å†—ä½™ä¿¡æ¯")
        md_content.append("")
        md_content.append("---")
        md_content.append("")
        md_content.append("*ğŸ“‹ æ­¤æŠ¥å‘Šç”±RUN_THIS_TOOL.py v4.0 (æ™ºèƒ½è¿‡æ»¤ç‰ˆ) è‡ªåŠ¨ç”Ÿæˆ*")
        md_content.append(f"*ğŸ”„ åŸºäºå¤šAgentåä½œçš„æ™ºèƒ½åˆ†æç»“æœ*")

        return "\n".join(md_content)

    def save_smart_markdown_report(self, report: Dict[str, Any], output_path: str):
        """ä¿å­˜æ™ºèƒ½èšç„¦çš„Markdownæ ¼å¼æŠ¥å‘Š"""
        try:
            markdown_content = self.generate_smart_markdown_report(report)
            # ç¡®ä¿æ–‡ä»¶æœ«å°¾æœ‰æ¢è¡Œç¬¦
            if not markdown_content.endswith("\n"):
                markdown_content += "\n"
            with open(output_path, "w", encoding="utf-8") as f:
                f.write(markdown_content)
            print(f"âœ… æ™ºèƒ½èšç„¦MarkdownæŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")
        except Exception as e:
            print(f"âŒ ä¿å­˜MarkdownæŠ¥å‘Šå¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•° - æ‰§è¡Œæ™ºèƒ½IOåˆ†é…å¯¹æ¯”åˆ†æ"""

    # æ–‡æ¡£è·¯å¾„
    doc_path = os.path.join(
        os.path.dirname(__file__), "../../docs/LifeSmart æ™ºæ…§è®¾å¤‡è§„æ ¼å±æ€§è¯´æ˜.md"
    )

    # è¾“å‡ºè·¯å¾„
    json_output_path = os.path.join(
        os.path.dirname(__file__), "smart_analysis_report.json"
    )
    markdown_output_path = os.path.join(
        os.path.dirname(__file__), "SMART_ANALYSIS_SUMMARY.md"
    )

    # åˆ›å»ºæ™ºèƒ½åˆ†æå™¨å¹¶æ‰§è¡Œåˆ†æ
    analyzer = SmartIOAllocationAnalyzer(enable_performance_monitoring=True)

    try:
        # æ‰§è¡Œæ™ºèƒ½å¯¹æ¯”åˆ†æ
        report = analyzer.perform_smart_comparison_analysis(doc_path)

        # ä¿å­˜JSONæŠ¥å‘Š
        analyzer.save_analysis_report(report, json_output_path)

        # ä¿å­˜æ™ºèƒ½èšç„¦MarkdownæŠ¥å‘Š
        analyzer.save_smart_markdown_report(report, markdown_output_path)

        # æ‰“å°å…³é”®ç»Ÿè®¡ä¿¡æ¯
        print("\\n" + "=" * 80)
        print("ğŸ¯ æ™ºèƒ½IOåˆ†é…å¯¹æ¯”åˆ†æç»“æœæ¦‚è§ˆ")
        print("=" * 80)

        overview = report["åˆ†ææ¦‚è§ˆ"]
        print(f"åˆ†ææ¨¡å¼: {overview['åˆ†ææ¨¡å¼']}")
        print(f"æ€»è®¾å¤‡æ•°: {overview['æ€»è®¾å¤‡æ•°']}")
        print(f"éœ€è¦å…³æ³¨è®¾å¤‡æ•°: {overview['éœ€è¦å…³æ³¨è®¾å¤‡æ•°']}")
        print(f"å·²è¿‡æ»¤è®¾å¤‡æ•°: {overview['å·²è¿‡æ»¤è®¾å¤‡æ•°']}")
        print(f"AI TokenèŠ‚çœç‡: {overview['AI TokenèŠ‚çœç‡']}")

        # æ˜¾ç¤ºæ™ºèƒ½è¿‡æ»¤æˆæ•ˆ
        filtering = report["æ™ºèƒ½è¿‡æ»¤ç»“æœ"]
        print(f"\\nğŸ¤– æ™ºèƒ½è¿‡æ»¤æˆæ•ˆ:")
        print(f"  èŠ‚çœAI Token: {filtering['èŠ‚çœçš„AI Token']}ä¸ªè®¾å¤‡")
        print(f"  èšç„¦å·®å¼‚è®¾å¤‡: {filtering['èšç„¦çš„å·®å¼‚è®¾å¤‡']}ä¸ªè®¾å¤‡")

        # æ˜¾ç¤ºå·®å¼‚è®¾å¤‡åˆ†æ
        diff_analysis = report["å·®å¼‚è®¾å¤‡åˆ†æ"]
        print(f"\\nğŸ” å·®å¼‚è®¾å¤‡åˆ†ç±»:")
        for priority_level, info in diff_analysis.items():
            if info["æ•°é‡"] > 0:
                print(f"  {priority_level}: {info['æ•°é‡']}ä¸ª")

        # æ˜¾ç¤ºæ ¸å¿ƒå‘ç°
        insights = report["æ ¸å¿ƒå‘ç°"]
        print(f"\\nğŸ’¡ æ ¸å¿ƒå‘ç°:")
        if insights.get("çŠ¶æ€"):
            print(f"  çŠ¶æ€: {insights['çŠ¶æ€']}")
        else:
            print(f"  ä¸»è¦é—®é¢˜ç±»å‹: {insights.get('ä¸»è¦é—®é¢˜ç±»å‹', 'N/A')}")
            print(f"  å¹³å‡ç½®ä¿¡åº¦: {insights.get('å¹³å‡ç½®ä¿¡åº¦', 'N/A')}")
            print(f"  æœ€éœ€å…³æ³¨è®¾å¤‡: {insights.get('æœ€éœ€å…³æ³¨è®¾å¤‡', 'N/A')}")

        # æ˜¾ç¤ºè¡ŒåŠ¨å»ºè®®
        recommendations = report["è¡ŒåŠ¨å»ºè®®"]
        if recommendations:
            print(f"\\nğŸ¯ ç«‹å³è¡ŒåŠ¨å»ºè®® (å‰{min(3, len(recommendations))}ä¸ª):")
            for i, rec in enumerate(recommendations[:3], 1):
                priority = rec["ä¼˜å…ˆçº§"]
                name = rec["è®¾å¤‡å"]
                confidence = rec["ç½®ä¿¡åº¦"]
                print(f"  {i}. {priority} {name}: ç½®ä¿¡åº¦ {confidence:.3f}")

        print("\\nâœ… æ™ºèƒ½åˆ†ææŠ¥å‘Šå·²ä¿å­˜:")
        print(f"   ğŸ“Š JSONè¯¦ç»†æŠ¥å‘Š: {json_output_path}")
        print(f"   ğŸ“‹ æ™ºèƒ½èšç„¦æŠ¥å‘Š: {markdown_output_path}")
        print(f"\\nğŸ¯ å‡çº§åŠŸèƒ½è¯´æ˜:")
        print(
            f"   ğŸ¤– å¤šAgentåä½œ: Agent1(ç°æœ‰åˆ†é…) + Agent2(AIå»ºè®®) + Agent3(å¯¹æ¯”åˆ†æ) + Agent4(æŠ¥å‘Šç”Ÿæˆ)"
        )
        print(f"   ğŸ¯ å·®å¼‚èšç„¦: åªå…³æ³¨éœ€è¦äººå·¥å¹²é¢„çš„ä¸ä¸€è‡´è®¾å¤‡")
        print(f"   ğŸ’° TokenèŠ‚çœ: æ™ºèƒ½è¿‡æ»¤100%åŒ¹é…çš„é«˜ç½®ä¿¡åº¦è®¾å¤‡")
        print(f"   ğŸš« æ— ç”¨æŠ¥å‘Šç§»é™¤: ä¸å†æ˜¾ç¤ºå¤šIOè®¾å¤‡å’ŒBitmaskè®¾å¤‡ç­‰æ— å…³ä¿¡æ¯")

    except Exception as e:
        print(f"âŒ æ™ºèƒ½åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    main()
